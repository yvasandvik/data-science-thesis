{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:33:27.265038Z",
     "iopub.status.busy": "2022-02-18T11:33:27.264809Z",
     "iopub.status.idle": "2022-02-18T11:33:28.373212Z",
     "shell.execute_reply": "2022-02-18T11:33:28.372392Z",
     "shell.execute_reply.started": "2022-02-18T11:33:27.264976Z"
    }
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): ['dlopen(/Users/yvaJsandvik/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yvaJsandvik/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-10707fd283d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Import the classifier we are using\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataIter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mlibname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         raise XGBoostError(\n\u001b[0m\u001b[1;32m    182\u001b[0m             f\"\"\"\n\u001b[1;32m    183\u001b[0m \u001b[0mXGBoost\u001b[0m \u001b[0mLibrary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlibname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mcould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): ['dlopen(/Users/yvaJsandvik/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yvaJsandvik/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing and encoding variables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the classifier we are using\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Visualising feature importance and making plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import multiple genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:33:28.375134Z",
     "iopub.status.busy": "2022-02-18T11:33:28.374849Z",
     "iopub.status.idle": "2022-02-18T11:37:00.541247Z",
     "shell.execute_reply": "2022-02-18T11:37:00.540423Z",
     "shell.execute_reply.started": "2022-02-18T11:33:28.375097Z"
    }
   },
   "outputs": [],
   "source": [
    "GG1 = pd.read_csv('~/Documents/NMBU/Semester 12/Data Science Master/data-science-thesis/data_expo/G1.features.csv').iloc[:, 1:]\n",
    "G2 = pd.read_csv('~/Documents/NMBU/Semester 12/Data Science Master/data-science-thesis/data_expo/G2.features.csv').iloc[:, 1:]\n",
    "G3 = pd.read_csv('~/Documents/NMBU/Semester 12/Data Science Master/data-science-thesis/data_expo/G3.features.csv').iloc[:, 1:]\n",
    "G4 = pd.read_csv('~/Documents/NMBU/Semester 12/Data Science Master/data-science-thesis/data_expo/G4.features.csv').iloc[:, 1:]\n",
    "G5 = pd.read_csv('~/Documents/NMBU/Semester 12/Data Science Master/data-science-thesis/data_expo/G5.features.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:37:00.542730Z",
     "iopub.status.busy": "2022-02-18T11:37:00.542478Z",
     "iopub.status.idle": "2022-02-18T11:37:01.952942Z",
     "shell.execute_reply": "2022-02-18T11:37:01.952024Z",
     "shell.execute_reply.started": "2022-02-18T11:37:00.542697Z"
    }
   },
   "outputs": [],
   "source": [
    "G1 = G1.sample(3000)\n",
    "G2 = G2.sample(3000)\n",
    "G3 = G3.sample(3000)\n",
    "G4 = G4.sample(3000)\n",
    "G5 = G5.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:37:01.955738Z",
     "iopub.status.busy": "2022-02-18T11:37:01.955450Z",
     "iopub.status.idle": "2022-02-18T11:37:05.749237Z",
     "shell.execute_reply": "2022-02-18T11:37:05.748524Z",
     "shell.execute_reply.started": "2022-02-18T11:37:01.955700Z"
    }
   },
   "outputs": [],
   "source": [
    "frames = [G1, G2, G3, G4, G5]\n",
    "df = pd.concat(frames)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:37:05.751414Z",
     "iopub.status.busy": "2022-02-18T11:37:05.750344Z",
     "iopub.status.idle": "2022-02-18T11:37:05.756807Z",
     "shell.execute_reply": "2022-02-18T11:37:05.755947Z",
     "shell.execute_reply.started": "2022-02-18T11:37:05.751373Z"
    }
   },
   "outputs": [],
   "source": [
    "G = df\n",
    "print('The shape of our dataframe is:', G.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:37:05.758659Z",
     "iopub.status.busy": "2022-02-18T11:37:05.758394Z",
     "iopub.status.idle": "2022-02-18T11:37:08.121363Z",
     "shell.execute_reply": "2022-02-18T11:37:08.120537Z",
     "shell.execute_reply.started": "2022-02-18T11:37:05.758624Z"
    }
   },
   "outputs": [],
   "source": [
    "G = G.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import single genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pd.read_csv('../input/genomespart2/G15.features.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G[[\"Length\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of our dataframe is:', G.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G.dropna()\n",
    "print('The shape of our dataframe is:', G.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:39:53.318504Z",
     "iopub.status.busy": "2022-02-18T11:39:53.317666Z",
     "iopub.status.idle": "2022-02-18T11:39:53.323618Z",
     "shell.execute_reply": "2022-02-18T11:39:53.322607Z",
     "shell.execute_reply.started": "2022-02-18T11:39:53.318458Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_feature(array):\n",
    "    \"\"\" Encode a categorical array into a number array\n",
    "    \n",
    "    :param array: array to be encoded\n",
    "    :return: numerical array\n",
    "    \"\"\"\n",
    "  \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(array)\n",
    "    return encoder.transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:39:54.444919Z",
     "iopub.status.busy": "2022-02-18T11:39:54.444650Z",
     "iopub.status.idle": "2022-02-18T11:39:54.454964Z",
     "shell.execute_reply": "2022-02-18T11:39:54.454180Z",
     "shell.execute_reply.started": "2022-02-18T11:39:54.444889Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['CDS', 'LORF']\n",
    "targets = G[\"Type\"].values\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:39:55.404684Z",
     "iopub.status.busy": "2022-02-18T11:39:55.404068Z",
     "iopub.status.idle": "2022-02-18T11:39:55.413946Z",
     "shell.execute_reply": "2022-02-18T11:39:55.412883Z",
     "shell.execute_reply.started": "2022-02-18T11:39:55.404642Z"
    }
   },
   "outputs": [],
   "source": [
    "targets = encode_feature(targets)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:39:56.482590Z",
     "iopub.status.busy": "2022-02-18T11:39:56.482011Z",
     "iopub.status.idle": "2022-02-18T11:39:56.488616Z",
     "shell.execute_reply": "2022-02-18T11:39:56.487772Z",
     "shell.execute_reply.started": "2022-02-18T11:39:56.482549Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of our dataframe is:', G.shape)\n",
    "print('Rows:', G.shape[0])\n",
    "print('Columns:', G.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting features and targets and converting data to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:39:59.323230Z",
     "iopub.status.busy": "2022-02-18T11:39:59.322939Z",
     "iopub.status.idle": "2022-02-18T11:40:02.336828Z",
     "shell.execute_reply": "2022-02-18T11:40:02.335937Z",
     "shell.execute_reply.started": "2022-02-18T11:39:59.323197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = targets\n",
    "\n",
    "# Remove the labels from the features -> axis 1 refers to the columns\n",
    "features = G.drop(['Type','Genome', 'Dataset'], axis = 1)\n",
    "\n",
    "# Saving feature names as list for later use\n",
    "feature_names = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:40:04.378132Z",
     "iopub.status.busy": "2022-02-18T11:40:04.377562Z",
     "iopub.status.idle": "2022-02-18T11:40:04.382931Z",
     "shell.execute_reply": "2022-02-18T11:40:04.381894Z",
     "shell.execute_reply.started": "2022-02-18T11:40:04.378090Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of our features are:', features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:40:07.987221Z",
     "iopub.status.busy": "2022-02-18T11:40:07.986667Z",
     "iopub.status.idle": "2022-02-18T11:40:15.936710Z",
     "shell.execute_reply": "2022-02-18T11:40:15.935827Z",
     "shell.execute_reply.started": "2022-02-18T11:40:07.987173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets -> x = features and y = labels/targets\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:40:17.875440Z",
     "iopub.status.busy": "2022-02-18T11:40:17.874848Z",
     "iopub.status.idle": "2022-02-18T11:40:17.886289Z",
     "shell.execute_reply": "2022-02-18T11:40:17.885407Z",
     "shell.execute_reply.started": "2022-02-18T11:40:17.875396Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_x.shape)\n",
    "print('Training Labels Shape:', train_y.shape)\n",
    "print('Testing Features Shape:', test_x.shape)\n",
    "print('Testing Labels Shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - default XGBoost\n",
    "\n",
    "- **learning_rate**: step size shrinkage used to prevent overfitting. Range is [0,1]\n",
    "- **max_depth**: determines how deeply each tree is allowed to grow during any boosting round.\n",
    "- **subsample**: percentage of samples used per tree. Low value can lead to underfitting.\n",
    "- **colsample_bytree**: percentage of features used per tree. High value can lead to overfitting.\n",
    "- **n_estimators**: number of trees you want to build.\n",
    "- **objective**: determines the loss function to be used like reg:linear for regression problems, reg:logistic for classification problems with only decision, binary:logistic for classification problems with probability. XGBoost also supports regularization parameters to penalize models as they become more complex and reduce them to simple (parsimonious) models.\n",
    "\n",
    "- **gamma**: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. Supported only for tree-based learners.\n",
    "- **alpha**: L1 regularization on leaf weights. A large value leads to more regularization.\n",
    "- **lambda**: L2 regularization on leaf weights and is smoother than L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T11:40:24.416153Z",
     "iopub.status.busy": "2022-02-18T11:40:24.415397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Gaussian Classifier\n",
    "xgb = XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# Train the model using the training sets \n",
    "xgb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for test data\n",
    "y_pred = xgb.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "print(\"Accuracy score:\", metrics.accuracy_score(test_y, y_pred))\n",
    "# Precision, Recall and Roc_AUC score\n",
    "#print(\"Precision score:\", metrics.precision_score(test_y, y_pred))\n",
    "#print(\"Recall score:\", metrics.recall_score(test_y, y_pred))\n",
    "#print(\"ROC_AUC score:\", metrics.roc_auc_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(xgb, test_x, test_y)  \n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('confmatrix_g1_uneven.png', dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamter searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "params = {\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "}\n",
    "\n",
    "xgb_search = RandomizedSearchCV(xgb, param_distributions=params, random_state=42, n_iter=10, cv=3, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "xgb_search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_best_scores(xgb_search.cv_results_, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If more than one evaluation metric are given the last one is used for early stopping\n",
    "xgb_model = XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric=\"auc\", use_label_encoder=False)\n",
    "\n",
    "xgb_model.fit(train_x, train_y, early_stopping_rounds=5, eval_set=[(test_x, test_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(test_x)\n",
    "\n",
    "# Evaluate predictions\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "print(\"Accuracy: %.4f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best score: {0}, best iteration: {1}, best ntree limit {2}\".format(xgb_model.best_score, xgb_model.best_iteration, xgb_model.best_ntree_limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train new model with best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is ntree limit = n_estimators or max_depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gaussian Classifier\n",
    "xgb = XGBClassifier(n_estimators=29, objective=\"binary:logistic\", random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# Train the model using the training sets \n",
    "xgb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for test data\n",
    "y_pred = xgb.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "print(\"Accuracy score:\", metrics.accuracy_score(test_y, y_pred))\n",
    "# Precision, Recall and Roc_AUC score\n",
    "print(\"Precision score:\", metrics.precision_score(test_y, y_pred))\n",
    "print(\"Recall score:\", metrics.recall_score(test_y, y_pred))\n",
    "print(\"ROC_AUC score:\", metrics.roc_auc_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(xgb.feature_importances_, index = feature_names).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = feature_imp.iloc[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = list(selected.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_indices = [feature_names.index(x) for x in selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gaussian Classifier\n",
    "xgb_select = XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# Select most important features\n",
    "important_indices = [feature_names.index(x) for x in selected_feat]\n",
    "\n",
    "train_important = train_x[:, important_indices]\n",
    "test_important = test_x[:, important_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training sets \n",
    "xgb_select.fit(train_important, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and determine the error\n",
    "pred_y = xgb_select.predict(test_important)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy score:\", metrics.accuracy_score(test_y, pred_y))\n",
    "# Precision, Recall and Roc_AUC score\n",
    "print(\"Precision score:\", metrics.precision_score(test_y, pred_y))\n",
    "print(\"Recall score:\", metrics.recall_score(test_y, pred_y))\n",
    "print(\"ROC_AUC score:\", metrics.roc_auc_score(test_y, pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
