{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Random Forest Model\n\nRF model to be used for predicting protein coding genes in DNA sequences.\n\n**Random Search with CV**\n- bootstrap': False\n- max_depth': 20\n- max_features': 'auto'\n- min_samples_leaf': 1\n- min_samples_split': 2\n- n_estimators': 1000\n \n**Grid Search with CV**\n- bootstrap': False\n- max_depth': 40\n- max_features': 3\n- min_samples_leaf': 1\n- min_samples_split': 2\n- n_estimators': 2000\n\nBEST MODEL G1 (high default score):\n- Random Search with CV - BUT\n- n_estimators': 200\n- n_features: 200\n\nBEST MODEL G2 (low default score):\n- Random search with CV\n- n_estimators': 1000\n- max_features': 'auto'\n- max_depth': 10\n- bootstrap': False","metadata":{}},{"cell_type":"markdown","source":"## Import packages and choose data","metadata":{}},{"cell_type":"code","source":"# Preprocessing and encoding variables\nimport pandas as pd\nimport numpy as np\nfrom random import sample\nfrom time import time\nimport sklearn\n\n# Using Skicit-learn to split data into training and testing sets\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\n# Import the model we are using\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n\n# Visualising feature importance and making plots\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\n\n# Hyperparameter tuning\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix, precision_score, recall_score, roc_auc_score\n\n# Selecting best features\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.feature_selection import SelectFromModel","metadata":{"execution":{"iopub.status.busy":"2022-05-09T13:46:16.418385Z","iopub.execute_input":"2022-05-09T13:46:16.418679Z","iopub.status.idle":"2022-05-09T13:46:16.426748Z","shell.execute_reply.started":"2022-05-09T13:46:16.418648Z","shell.execute_reply":"2022-05-09T13:46:16.425537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns. __version__","metadata":{"execution":{"iopub.status.busy":"2022-05-09T13:46:38.089909Z","iopub.execute_input":"2022-05-09T13:46:38.090237Z","iopub.status.idle":"2022-05-09T13:46:38.097111Z","shell.execute_reply.started":"2022-05-09T13:46:38.090199Z","shell.execute_reply":"2022-05-09T13:46:38.096087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Combining 5 genomes","metadata":{}},{"cell_type":"code","source":"G1 = pd.read_csv('../input/genomes-part1/G1.features.csv').iloc[:, 1:]\nG2 = pd.read_csv('../input/genomes-part1/G2.features.csv').iloc[:, 1:]\nG3 = pd.read_csv('../input/genomes-part1/G3.features.csv').iloc[:, 1:]\nG4 = pd.read_csv('../input/genomes-part1/G4.features.csv').iloc[:, 1:]\nG5 = pd.read_csv('../input/genomes-part1/G5.features.csv').iloc[:, 1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G1 = G1.sample(2000)\nG2 = G2.sample(2000)\nG3 = G3.sample(2000)\nG4 = G4.sample(2000)\nG5 = G5.sample(2000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frames = [G1, G2, G3, G4, G5]\ndf = pd.concat(frames)\ndf.tail(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G = df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Single genome","metadata":{}},{"cell_type":"code","source":"G = pd.read_csv('../input/genomespart2/G15.features.csv').iloc[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:26:56.784614Z","iopub.execute_input":"2022-05-04T11:26:56.784861Z","iopub.status.idle":"2022-05-04T11:28:12.019619Z","shell.execute_reply.started":"2022-05-04T11:26:56.784832Z","shell.execute_reply":"2022-05-04T11:28:12.018295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:28:12.021225Z","iopub.execute_input":"2022-05-04T11:28:12.021486Z","iopub.status.idle":"2022-05-04T11:28:12.069146Z","shell.execute_reply.started":"2022-05-04T11:28:12.021457Z","shell.execute_reply":"2022-05-04T11:28:12.067924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-processing / Data preparation\n\n1. One-hot encoded categorical variables\n2. Split data into features and labels\n3. Convert to arrays\n4. Split data into training and testing sets","metadata":{}},{"cell_type":"code","source":"print('The shape of our dataframe is:', G.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:26.389946Z","iopub.execute_input":"2022-03-03T17:08:26.390192Z","iopub.status.idle":"2022-03-03T17:08:26.39758Z","shell.execute_reply.started":"2022-03-03T17:08:26.390164Z","shell.execute_reply":"2022-03-03T17:08:26.396399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G = G.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:26.39923Z","iopub.execute_input":"2022-03-03T17:08:26.400502Z","iopub.status.idle":"2022-03-03T17:08:27.639882Z","shell.execute_reply.started":"2022-03-03T17:08:26.400397Z","shell.execute_reply":"2022-03-03T17:08:27.639059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The shape of our dataframe is:', G.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:27.641841Z","iopub.execute_input":"2022-03-03T17:08:27.642103Z","iopub.status.idle":"2022-03-03T17:08:27.648217Z","shell.execute_reply.started":"2022-03-03T17:08:27.642055Z","shell.execute_reply":"2022-03-03T17:08:27.647336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding target values","metadata":{}},{"cell_type":"code","source":"def encode_feature(array):\n    \"\"\" Encode a categorical array into a number array\n    \n    :param array: array to be encoded\n    :return: numerical array\n    \"\"\"\n  \n    encoder = preprocessing.LabelEncoder()\n    encoder.fit(array)\n    return encoder.transform(array)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:27.649799Z","iopub.execute_input":"2022-03-03T17:08:27.650062Z","iopub.status.idle":"2022-03-03T17:08:27.661116Z","shell.execute_reply.started":"2022-03-03T17:08:27.650031Z","shell.execute_reply":"2022-03-03T17:08:27.66039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['CDS', 'LORF']\ntargets = G[\"Type\"].values\nprint(targets)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:27.66277Z","iopub.execute_input":"2022-03-03T17:08:27.663069Z","iopub.status.idle":"2022-03-03T17:08:27.687008Z","shell.execute_reply.started":"2022-03-03T17:08:27.663026Z","shell.execute_reply":"2022-03-03T17:08:27.686012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = encode_feature(targets)\nprint(targets)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:27.688628Z","iopub.execute_input":"2022-03-03T17:08:27.689823Z","iopub.status.idle":"2022-03-03T17:08:27.703436Z","shell.execute_reply.started":"2022-03-03T17:08:27.689766Z","shell.execute_reply":"2022-03-03T17:08:27.702248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The shape of our dataframe is:', G.shape)\nprint('Rows:', G.shape[0])\nprint('Columns:', G.shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:27.705334Z","iopub.execute_input":"2022-03-03T17:08:27.705965Z","iopub.status.idle":"2022-03-03T17:08:27.720333Z","shell.execute_reply.started":"2022-03-03T17:08:27.705918Z","shell.execute_reply":"2022-03-03T17:08:27.718948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selecting features and targets and converting data to arrays","metadata":{}},{"cell_type":"code","source":"# Labels are the values we want to predict\nlabels = targets\n\n# Remove the labels from the features -> axis 1 refers to the columns\nfeatures = G.drop(['Type','Genome', 'Dataset'], axis = 1)\n\n# Saving feature names as list for later use\nfeature_names = list(features.columns)\n\n# Convert to numpy array\nfeatures = np.array(features)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:27.722129Z","iopub.execute_input":"2022-03-03T17:08:27.722407Z","iopub.status.idle":"2022-03-03T17:08:29.555701Z","shell.execute_reply.started":"2022-03-03T17:08:27.722375Z","shell.execute_reply":"2022-03-03T17:08:29.554455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The shape of our features are:', features.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:29.559558Z","iopub.execute_input":"2022-03-03T17:08:29.559838Z","iopub.status.idle":"2022-03-03T17:08:29.566709Z","shell.execute_reply.started":"2022-03-03T17:08:29.559808Z","shell.execute_reply":"2022-03-03T17:08:29.565405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split into training and testing sets","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets -> x = features and y = labels/targets\ntrain_x, test_x, train_y, test_y = train_test_split(features, labels, test_size = 0.25, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:29.568074Z","iopub.execute_input":"2022-03-03T17:08:29.569327Z","iopub.status.idle":"2022-03-03T17:08:31.820828Z","shell.execute_reply.started":"2022-03-03T17:08:29.569225Z","shell.execute_reply":"2022-03-03T17:08:31.820159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training Features Shape:', train_x.shape)\nprint('Training Labels Shape:', train_y.shape)\nprint('Testing Features Shape:', test_x.shape)\nprint('Testing Labels Shape:', test_y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:31.822451Z","iopub.execute_input":"2022-03-03T17:08:31.822701Z","iopub.status.idle":"2022-03-03T17:08:31.832018Z","shell.execute_reply.started":"2022-03-03T17:08:31.82267Z","shell.execute_reply":"2022-03-03T17:08:31.830589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model - default Rand Forest\n\n**RandomForestClassifier**(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)","metadata":{}},{"cell_type":"code","source":"# Create a Gaussian Classifier\nclf = RandomForestClassifier(random_state = 42, n_jobs=-1)\n\n# Train the model using the training sets\nclf.fit(train_x, train_y)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:31.833728Z","iopub.execute_input":"2022-03-03T17:08:31.834022Z","iopub.status.idle":"2022-03-03T17:08:53.521741Z","shell.execute_reply.started":"2022-03-03T17:08:31.833987Z","shell.execute_reply":"2022-03-03T17:08:53.520428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make predictions on test set","metadata":{}},{"cell_type":"code","source":"pred_y = clf.predict(test_x)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:53.523879Z","iopub.execute_input":"2022-03-03T17:08:53.525112Z","iopub.status.idle":"2022-03-03T17:08:53.938005Z","shell.execute_reply.started":"2022-03-03T17:08:53.525031Z","shell.execute_reply":"2022-03-03T17:08:53.937147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparametertuning","metadata":{}},{"cell_type":"code","source":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)]\n\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 70, num = 10)]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'bootstrap': bootstrap}\n\nprint(random_grid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random search of parameters, using 3 fold cross validation\nclf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 10,\n                               cv = 3, verbose=2, random_state=42, n_jobs = -1, return_train_score=True)\n\n# Fit the random search model\nclf_random.fit(train_x, train_y);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_random.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make predictions on test set","metadata":{}},{"cell_type":"code","source":"pred_y = clf_random.predict(test_x)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy after random search:\",metrics.accuracy_score(test_y, pred_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate functions","metadata":{}},{"cell_type":"code","source":"def evaluate(model, test_features, test_lables):\n    predictions = model.predict(test_features)\n    accuracy = metrics.accuracy_score(test_lables, predictions)\n    print('Model Performance')\n    print('Accuracy = {:0.4f}%.'.format(accuracy))\n    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Default model","metadata":{}},{"cell_type":"code","source":"base_accuracy = evaluate(clf, test_x, test_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Best random search model","metadata":{}},{"cell_type":"code","source":"best_random = clf_random.best_estimator_\nrandom_accuracy = evaluate(best_random, test_x, test_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Improvement of {:0.3f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model - best params RandomSearch","metadata":{}},{"cell_type":"code","source":"# Create a Gaussian Classifier\nclf_rand = RandomForestClassifier(n_estimators=200, max_features=3, max_depth=10, bootstrap=False, random_state = 42)\n\n# Train the model using the training sets\nclf_rand.fit(train_x, train_y)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:53.939806Z","iopub.execute_input":"2022-03-03T17:08:53.940336Z","iopub.status.idle":"2022-03-03T17:08:56.917435Z","shell.execute_reply.started":"2022-03-03T17:08:53.94029Z","shell.execute_reply":"2022-03-03T17:08:56.916179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make predictions on test set","metadata":{}},{"cell_type":"code","source":"pred_y = clf_rand.predict(test_x)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy score:\", metrics.accuracy_score(test_y, pred_y))\n\n# Precision, Recall and Roc_AUC score\nprint(\"Precision score:\", metrics.precision_score(test_y, pred_y))\nprint(\"Recall score:\", metrics.recall_score(test_y, pred_y))\nprint(\"ROC_AUC score:\", metrics.roc_auc_score(test_y, pred_y))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T17:08:56.919211Z","iopub.execute_input":"2022-03-03T17:08:56.919543Z","iopub.status.idle":"2022-03-03T17:08:57.220861Z","shell.execute_reply.started":"2022-03-03T17:08:56.919499Z","shell.execute_reply":"2022-03-03T17:08:57.219878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion matrix","metadata":{}},{"cell_type":"code","source":"plot_confusion_matrix(clf_rand, test_x, test_y)  \nplt.show()\n\n#plt.savefig('confmatrix_g1_uneven.png', dpi=300, bbox_inches='tight', transparent=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding important features\n\n1. Create a random forests model.\n2. Use the feature importance variable to see feature importance scores.\n3. Visualize these scores using the seaborn library.","metadata":{}},{"cell_type":"code","source":"feature_imp = pd.Series(clf_rand.feature_importances_, index = feature_names).sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = feature_imp.to_frame()\nfeatures.columns = ['Feature importance']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grouping all k-mers\ndimers = features[features.index.map(lambda x: \"2_mer_\" in x)]\ntrimers = features[features.index.map(lambda x: \"3_mer_\" in x)]\ntetramers = features[features.index.map(lambda x: \"4_mer_\" in x)]\npentamers = features[features.index.map(lambda x: \"5_mer_\" in x)] \nhexamers = features[features.index.map(lambda x: \"6_mer_\" in x)]\n\n# Grouping all aa-mers\nsingle_aa = features[features.index.map(lambda x: \"1_aa_mer_\" in x)]\ndouble_aa = features[features.index.map(lambda x: \"2_aa_mer_\" in x)]\ntriple_aa = features[features.index.map(lambda x: \"3_aa_mer_\" in x)]\n\n# Grouping c_weights\nc_weight = features[features.index.map(lambda x: \"c_weight\" in x)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Mean feature importances of all k-mers, aa-mers and c_weights","metadata":{}},{"cell_type":"code","source":"data = {'Feature importance': [round(dimers.mean().iloc[0], 6), round(trimers.mean().iloc[0], 6), \n                               round(tetramers.mean().iloc[0], 6), round(pentamers.mean().iloc[0], 6), \n                               round(hexamers.mean().iloc[0], 6), round(single_aa.mean().iloc[0], 6), \n                               round(double_aa.mean().iloc[0], 6), round(triple_aa.mean().iloc[0], 6),\n                               round(c_weight.mean().iloc[0], 6)]}\n\nfeatures_cond = pd.DataFrame(data, index = ['dimers', 'trimers', 'tetramers', 'pentamers', 'hexamers', \n                                            'single_aa', 'double_aa', 'triple_aa', 'c_weight'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Sum of all feature importances of k-mers, aa-mers and c_weights","metadata":{}},{"cell_type":"code","source":"data = {'Feature importance': [round(dimers.sum().iloc[0], 6), round(trimers.sum().iloc[0], 6), \n                               round(tetramers.sum().iloc[0], 6), round(pentamers.sum().iloc[0], 6), \n                               round(hexamers.sum().iloc[0], 6), round(single_aa.sum().iloc[0], 6), \n                               round(double_aa.sum().iloc[0], 6), round(triple_aa.sum().iloc[0], 6),\n                               round(c_weight.sum().iloc[0], 6)]}\n\nfeatures_cond2 = pd.DataFrame(data, index = ['dimers', 'trimers', 'tetramers', 'pentamers', 'hexamers', \n                                            'single_aa', 'double_aa', 'triple_aa', 'c_weight'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_cond","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind_list = ['GC_content', 'GC1_content', 'GC2_content', 'GC3_content', \n            'Start_ATG', 'Start_GTG', 'Start_TTG', 'Length']\n\nfeatures_condensed = features.loc[ind_list]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_condensed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_red = pd.concat([features_condensed, features_cond])\nfeatures_red = features_red.squeeze()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_red = features_red.sort_values(ascending=False)\nfeatures_red","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_red2 = pd.concat([features_condensed, features_cond2])\nfeatures_red2 = features_red2.squeeze()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_red2 = features_red2.sort_values(ascending=False)\ntype(features_red2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\n# Creating a bar plot\nsns.barplot(x = features_red, y = features_red.index)\n\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features (mean)\")\n#plt.savefig('feat_imp_g15_1.png', dpi=300, bbox_inches='tight', transparent=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\n# Creating a bar plot\nsns.barplot(x = features_red2, y = features_red2.index)\n\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features (sum)\")\n#plt.savefig('feat_imp_g15_2.png', dpi=300, bbox_inches='tight', transparent=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nfeatures_condensed = features_condensed.squeeze().sort_values(ascending=False)\n\n# Creating a bar plot\nsns.barplot(x = features_condensed, y = features_condensed.index)\n\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualization","metadata":{}},{"cell_type":"code","source":"feature_imp = pd.Series(clf_rand.feature_importances_, index = feature_names).sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected = feature_imp.iloc[0:15]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\n# Creating a bar plot\nsns.barplot(x = selected, y = selected.index)\n\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\n#plt.savefig('feat_imp_g15_3.png', dpi=300, bbox_inches='tight', transparent=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating the model on selected features\n\nAfter removing the least important features the accuracy may increase. This is because one removes misleading data and noise, resulting in increased accuracy. A lesser amount of features also reduces the training time.","metadata":{}},{"cell_type":"code","source":"feature_imp = pd.Series(clf_rand.feature_importances_, index = feature_names).sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected = feature_imp.iloc[0:200]\nselected_feat = list(selected.index)\nimportant_indices = [feature_names.index(x) for x in selected_feat]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a Gaussian Classifier\nclf_imp = RandomForestClassifier(n_estimators=200, max_features='auto', \n                             max_depth=10, bootstrap=False, random_state = 42)\n\n# Select most important features\nimportant_indices = [feature_names.index(x) for x in selected_feat]\n\ntrain_important = train_x[:, important_indices]\ntest_important = test_x[:, important_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the random forest\nclf_imp.fit(train_important, train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions and determine the error\npred_y = clf_imp.predict(test_important)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy score:\", metrics.accuracy_score(test_y, pred_y))\n# Precision, Recall and Roc_AUC score\nprint(\"Precision score:\", metrics.precision_score(test_y, pred_y))\nprint(\"Recall score:\", metrics.recall_score(test_y, pred_y))\nprint(\"ROC_AUC score:\", metrics.roc_auc_score(test_y, pred_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Confusion matrix","metadata":{}},{"cell_type":"code","source":"plot_confusion_matrix(clf_imp, test_important, test_y)  \nplt.show()\n\n#plt.savefig('confmatrix_g1_bestmod_uneven.png', dpi=300, bbox_inches='tight', transparent=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:24:21.896717Z","iopub.execute_input":"2022-05-03T09:24:21.897593Z","iopub.status.idle":"2022-05-03T09:24:22.001919Z","shell.execute_reply.started":"2022-05-03T09:24:21.897453Z","shell.execute_reply":"2022-05-03T09:24:22.000571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}