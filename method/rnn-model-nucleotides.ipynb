{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb1b738",
   "metadata": {
    "papermill": {
     "duration": 0.026963,
     "end_time": "2022-05-07T10:21:07.891938",
     "exception": false,
     "start_time": "2022-05-07T10:21:07.864975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Simple RNN model - raw sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c41126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:07.955643Z",
     "iopub.status.busy": "2022-05-07T10:21:07.954834Z",
     "iopub.status.idle": "2022-05-07T10:21:14.236828Z",
     "shell.execute_reply": "2022-05-07T10:21:14.236211Z"
    },
    "papermill": {
     "duration": 6.319156,
     "end_time": "2022-05-07T10:21:14.236987",
     "exception": false,
     "start_time": "2022-05-07T10:21:07.917831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing and encoding variables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For characterlevel one hot encoding or label encoding \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Activation\n",
    "import tensorflow.keras.utils as utils\n",
    "from keras import optimizers\n",
    "\n",
    "# For RNN architecture\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc38e1",
   "metadata": {
    "papermill": {
     "duration": 0.022239,
     "end_time": "2022-05-07T10:21:14.282329",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.260090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Uploading genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42697fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:14.332903Z",
     "iopub.status.busy": "2022-05-07T10:21:14.332245Z",
     "iopub.status.idle": "2022-05-07T10:21:14.460084Z",
     "shell.execute_reply": "2022-05-07T10:21:14.458855Z"
    },
    "papermill": {
     "duration": 0.154823,
     "end_time": "2022-05-07T10:21:14.460241",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.305418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = pd.read_csv('../input/genomes/G1_translated.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c94d068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:14.522161Z",
     "iopub.status.busy": "2022-05-07T10:21:14.521217Z",
     "iopub.status.idle": "2022-05-07T10:21:14.525843Z",
     "shell.execute_reply": "2022-05-07T10:21:14.525328Z"
    },
    "papermill": {
     "duration": 0.039676,
     "end_time": "2022-05-07T10:21:14.525972",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.486296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = G.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f92325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:14.584597Z",
     "iopub.status.busy": "2022-05-07T10:21:14.583869Z",
     "iopub.status.idle": "2022-05-07T10:21:14.596959Z",
     "shell.execute_reply": "2022-05-07T10:21:14.596478Z"
    },
    "papermill": {
     "duration": 0.044211,
     "end_time": "2022-05-07T10:21:14.597081",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.552870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>CDS</td>\n",
       "      <td>GTGAAAGATTTATTAAAGTTTCTGAAAGCGCAGACTAAAACCGAAG...</td>\n",
       "      <td>VKDLLKFLKAQTKTEEFDAIKIALASPDMIRSWSFGEVKKPETINY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8640</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGAGCGGAAAACCGGCGGCGCGTCAGGGTGACATGACGCAGTATG...</td>\n",
       "      <td>MSGKPAARQGDMTQYGGSIVQGSAGVRIGAPTGVACSVCPGGVTSG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8641</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGAGCGGAAAACCAGCGGCGCGTCAGGGAGATATGACTCAGTATG...</td>\n",
       "      <td>MSGKPAARQGDMTQYGGPIVQGSAGVRIGAPTGVACSVCPGGMTSG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8642</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGATTGAACGCGGTAAATTTCGCTCACTGACGCTGATTAACTGGA...</td>\n",
       "      <td>MIERGKFRSLTLINWNGFFARTFDLDELVTTLSGGNGAGKSTTMAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8643</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGTTGTACGATAAATCCCTTGAGAGGGATAACTGTGGTTTCGGCC...</td>\n",
       "      <td>MLYDKSLERDNCGFGLIAHIEGEPSHKVVRTAIHALARMQHRGAIL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8644</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGAATAAGAAATTTAAATATAAGAAATCGCTTTTAGCGGCTATTT...</td>\n",
       "      <td>MNKKFKYKKSLLAAILSATLLAGCDGGGSGSSSDTPPVDSGTGSLP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8645</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGAACAGGACCAGTCCCTATTATTGTCGCCGCTCAGTACTTTCCT...</td>\n",
       "      <td>MNRTSPYYCRRSVLSLLISALIYAPPGMAAFTTNVIGVVNDETVDG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8646</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGGCAGATAATCCAGACCCTTCATCGCTCCTGCCGGACGTGTTTT...</td>\n",
       "      <td>MADNPDPSSLLPDVFSPATRDWFLRAFKQPTAVQPQTWHVAARSEH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8647</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGAAAAAGTTACGCGTAGCCGCCTGCATGCTAATGCTGGCGCTGG...</td>\n",
       "      <td>MKKLRVAACMLMLALAGCDNNDNAPTAVKKDAPSEVTKAASSENAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8648</th>\n",
       "      <td>CDS</td>\n",
       "      <td>ATGGCTACGAAGAAGAGAAGTGGAGAAGAAATAAATGACCGACAAA...</td>\n",
       "      <td>MATKKRSGEEINDRQILCGMGIKLRRLTAGICLITQLAFPMAAAAQ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type                                           Sequence  \\\n",
       "8639  CDS  GTGAAAGATTTATTAAAGTTTCTGAAAGCGCAGACTAAAACCGAAG...   \n",
       "8640  CDS  ATGAGCGGAAAACCGGCGGCGCGTCAGGGTGACATGACGCAGTATG...   \n",
       "8641  CDS  ATGAGCGGAAAACCAGCGGCGCGTCAGGGAGATATGACTCAGTATG...   \n",
       "8642  CDS  ATGATTGAACGCGGTAAATTTCGCTCACTGACGCTGATTAACTGGA...   \n",
       "8643  CDS  ATGTTGTACGATAAATCCCTTGAGAGGGATAACTGTGGTTTCGGCC...   \n",
       "8644  CDS  ATGAATAAGAAATTTAAATATAAGAAATCGCTTTTAGCGGCTATTT...   \n",
       "8645  CDS  ATGAACAGGACCAGTCCCTATTATTGTCGCCGCTCAGTACTTTCCT...   \n",
       "8646  CDS  ATGGCAGATAATCCAGACCCTTCATCGCTCCTGCCGGACGTGTTTT...   \n",
       "8647  CDS  ATGAAAAAGTTACGCGTAGCCGCCTGCATGCTAATGCTGGCGCTGG...   \n",
       "8648  CDS  ATGGCTACGAAGAAGAGAAGTGGAGAAGAAATAAATGACCGACAAA...   \n",
       "\n",
       "                                             Translated  \n",
       "8639  VKDLLKFLKAQTKTEEFDAIKIALASPDMIRSWSFGEVKKPETINY...  \n",
       "8640  MSGKPAARQGDMTQYGGSIVQGSAGVRIGAPTGVACSVCPGGVTSG...  \n",
       "8641  MSGKPAARQGDMTQYGGPIVQGSAGVRIGAPTGVACSVCPGGMTSG...  \n",
       "8642  MIERGKFRSLTLINWNGFFARTFDLDELVTTLSGGNGAGKSTTMAA...  \n",
       "8643  MLYDKSLERDNCGFGLIAHIEGEPSHKVVRTAIHALARMQHRGAIL...  \n",
       "8644  MNKKFKYKKSLLAAILSATLLAGCDGGGSGSSSDTPPVDSGTGSLP...  \n",
       "8645  MNRTSPYYCRRSVLSLLISALIYAPPGMAAFTTNVIGVVNDETVDG...  \n",
       "8646  MADNPDPSSLLPDVFSPATRDWFLRAFKQPTAVQPQTWHVAARSEH...  \n",
       "8647  MKKLRVAACMLMLALAGCDNNDNAPTAVKKDAPSEVTKAASSENAS...  \n",
       "8648  MATKKRSGEEINDRQILCGMGIKLRRLTAGICLITQLAFPMAAAAQ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fc7b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:14.650157Z",
     "iopub.status.busy": "2022-05-07T10:21:14.649366Z",
     "iopub.status.idle": "2022-05-07T10:21:14.652639Z",
     "shell.execute_reply": "2022-05-07T10:21:14.653225Z"
    },
    "papermill": {
     "duration": 0.032181,
     "end_time": "2022-05-07T10:21:14.653395",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.621214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our dataframe is: (8649, 3)\n",
      "Rows: 8649\n",
      "Columns: 3\n"
     ]
    }
   ],
   "source": [
    "print('The shape of our dataframe is:', G.shape)\n",
    "print('Rows:', G.shape[0])\n",
    "print('Columns:', G.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6349185",
   "metadata": {
    "papermill": {
     "duration": 0.02448,
     "end_time": "2022-05-07T10:21:14.702938",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.678458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encoding data\n",
    "\n",
    "Using sklearn OneHotEncoder and LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dfa58",
   "metadata": {
    "papermill": {
     "duration": 0.028876,
     "end_time": "2022-05-07T10:21:14.760888",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.732012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25dae8eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:14.825251Z",
     "iopub.status.busy": "2022-05-07T10:21:14.823524Z",
     "iopub.status.idle": "2022-05-07T10:21:14.825841Z",
     "shell.execute_reply": "2022-05-07T10:21:14.826261Z"
    },
    "papermill": {
     "duration": 0.036942,
     "end_time": "2022-05-07T10:21:14.826392",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.789450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_feature(array):\n",
    "    \"\"\" Encode a categorical array into a number array\n",
    "    \n",
    "    :param array: array to be encoded\n",
    "    :return: numerical array\n",
    "    \"\"\"\n",
    "  \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(array)\n",
    "    return encoder.transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9446eaf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:14.892088Z",
     "iopub.status.busy": "2022-05-07T10:21:14.891491Z",
     "iopub.status.idle": "2022-05-07T10:21:14.895523Z",
     "shell.execute_reply": "2022-05-07T10:21:14.894963Z"
    },
    "papermill": {
     "duration": 0.041448,
     "end_time": "2022-05-07T10:21:14.895673",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.854225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CDS' 'CDS' 'CDS' ... 'CDS' 'CDS' 'CDS']\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CDS', 'LORF']\n",
    "labels = G[\"Type\"].values\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7906caa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:14.953714Z",
     "iopub.status.busy": "2022-05-07T10:21:14.952781Z",
     "iopub.status.idle": "2022-05-07T10:21:14.956962Z",
     "shell.execute_reply": "2022-05-07T10:21:14.956521Z"
    },
    "papermill": {
     "duration": 0.035765,
     "end_time": "2022-05-07T10:21:14.957082",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.921317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = encode_feature(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b781030",
   "metadata": {
    "papermill": {
     "duration": 0.026348,
     "end_time": "2022-05-07T10:21:15.008635",
     "exception": false,
     "start_time": "2022-05-07T10:21:14.982287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Sequences\n",
    "\n",
    "The sequenes are are tokenized using keras tokenizer, then padded and finally one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18b18f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:15.065409Z",
     "iopub.status.busy": "2022-05-07T10:21:15.064744Z",
     "iopub.status.idle": "2022-05-07T10:21:15.067412Z",
     "shell.execute_reply": "2022-05-07T10:21:15.067842Z"
    },
    "papermill": {
     "duration": 0.033836,
     "end_time": "2022-05-07T10:21:15.067989",
     "exception": false,
     "start_time": "2022-05-07T10:21:15.034153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAAGGCTAA',\n",
       " 'AAAAAAGAGTGA',\n",
       " 'ATGAAAAATAGTGTCGCTGAGCACTAA',\n",
       " 'ATGATTAAATCCGACCAGGAGACCTGA',\n",
       " 'ATGCTTCATTGCAAAGGGAATAATCTATGA']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract sequences\n",
    "samples = G['Sequence'].values\n",
    "samples = list(samples)\n",
    "samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdedd8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:15.137483Z",
     "iopub.status.busy": "2022-05-07T10:21:15.136508Z",
     "iopub.status.idle": "2022-05-07T10:21:17.538828Z",
     "shell.execute_reply": "2022-05-07T10:21:17.538283Z"
    },
    "papermill": {
     "duration": 2.445752,
     "end_time": "2022-05-07T10:21:17.538965",
     "exception": false,
     "start_time": "2022-05-07T10:21:15.093213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenizer configured to only take into account the top-4 most common words\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "\n",
    "# This builds the word index\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "# This turns strings into lists of integer indices.\n",
    "seq_of_int = tokenizer.texts_to_sequences(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17be37b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:17.596416Z",
     "iopub.status.busy": "2022-05-07T10:21:17.595746Z",
     "iopub.status.idle": "2022-05-07T10:21:17.598420Z",
     "shell.execute_reply": "2022-05-07T10:21:17.598864Z"
    },
    "papermill": {
     "duration": 0.033854,
     "end_time": "2022-05-07T10:21:17.598998",
     "exception": false,
     "start_time": "2022-05-07T10:21:17.565144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 1, 1, 2, 3, 4, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_of_int[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898e6e43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:17.655858Z",
     "iopub.status.busy": "2022-05-07T10:21:17.655260Z",
     "iopub.status.idle": "2022-05-07T10:21:17.658194Z",
     "shell.execute_reply": "2022-05-07T10:21:17.658595Z"
    },
    "papermill": {
     "duration": 0.033765,
     "end_time": "2022-05-07T10:21:17.658720",
     "exception": false,
     "start_time": "2022-05-07T10:21:17.624955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence is: 7077\n"
     ]
    }
   ],
   "source": [
    "print('Longest sequence is:', len(samples[len(G)-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff93d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:17.717863Z",
     "iopub.status.busy": "2022-05-07T10:21:17.716789Z",
     "iopub.status.idle": "2022-05-07T10:21:18.281506Z",
     "shell.execute_reply": "2022-05-07T10:21:18.281034Z"
    },
    "papermill": {
     "duration": 0.596495,
     "end_time": "2022-05-07T10:21:18.281638",
     "exception": false,
     "start_time": "2022-05-07T10:21:17.685143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#max_len = len(samples[len(G)-1])\n",
    "max_len = 4000\n",
    "seq_padded = sequence.pad_sequences(seq_of_int, maxlen=max_len, dtype='int32', value=0.0) # if maxlen=None then the maximum lenght is the longest sequence in genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a656533c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:18.344833Z",
     "iopub.status.busy": "2022-05-07T10:21:18.344125Z",
     "iopub.status.idle": "2022-05-07T10:21:18.346973Z",
     "shell.execute_reply": "2022-05-07T10:21:18.347375Z"
    },
    "papermill": {
     "duration": 0.035546,
     "end_time": "2022-05-07T10:21:18.347504",
     "exception": false,
     "start_time": "2022-05-07T10:21:18.311958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8649, 4000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(seq_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3faad50",
   "metadata": {
    "papermill": {
     "duration": 0.02685,
     "end_time": "2022-05-07T10:21:18.401426",
     "exception": false,
     "start_time": "2022-05-07T10:21:18.374576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### OneHotEncode padded integer sequences\n",
    "\n",
    "The reason why we can not simply convert every character to its position in the alphabet, e.g. a — 1, b — 2 etc.) is that this would lead the network to assume that the characters are on an ordinal scale, instead of a categorical - the letter Z not is “worth more” than an A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24eb6d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:18.460792Z",
     "iopub.status.busy": "2022-05-07T10:21:18.459744Z",
     "iopub.status.idle": "2022-05-07T10:21:19.178415Z",
     "shell.execute_reply": "2022-05-07T10:21:19.177922Z"
    },
    "papermill": {
     "duration": 0.749724,
     "end_time": "2022-05-07T10:21:19.178544",
     "exception": false,
     "start_time": "2022-05-07T10:21:18.428820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_one_hot = utils.to_categorical(seq_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ae49bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:19.240524Z",
     "iopub.status.busy": "2022-05-07T10:21:19.239339Z",
     "iopub.status.idle": "2022-05-07T10:21:19.244530Z",
     "shell.execute_reply": "2022-05-07T10:21:19.243777Z"
    },
    "papermill": {
     "duration": 0.03799,
     "end_time": "2022-05-07T10:21:19.244711",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.206721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8649, 4000, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(seq_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461771a1",
   "metadata": {
    "papermill": {
     "duration": 0.031792,
     "end_time": "2022-05-07T10:21:19.308375",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.276583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc7629a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:19.378049Z",
     "iopub.status.busy": "2022-05-07T10:21:19.376682Z",
     "iopub.status.idle": "2022-05-07T10:21:19.422145Z",
     "shell.execute_reply": "2022-05-07T10:21:19.422619Z"
    },
    "papermill": {
     "duration": 0.083443,
     "end_time": "2022-05-07T10:21:19.422787",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.339344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets -> x = features and y = labels/targets\n",
    "train_x, test_x, train_y, test_y = train_test_split(seq_padded, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bcd3b32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:19.484380Z",
     "iopub.status.busy": "2022-05-07T10:21:19.483820Z",
     "iopub.status.idle": "2022-05-07T10:21:19.487433Z",
     "shell.execute_reply": "2022-05-07T10:21:19.488268Z"
    },
    "papermill": {
     "duration": 0.037326,
     "end_time": "2022-05-07T10:21:19.488405",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.451079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:\n",
      "6919 train sequences\n",
      "1730 test sequences\n"
     ]
    }
   ],
   "source": [
    "print('Input data:')\n",
    "print(len(train_x), 'train sequences')\n",
    "print(len(test_x), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9946316c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:19.551845Z",
     "iopub.status.busy": "2022-05-07T10:21:19.550960Z",
     "iopub.status.idle": "2022-05-07T10:21:19.553943Z",
     "shell.execute_reply": "2022-05-07T10:21:19.554418Z"
    },
    "papermill": {
     "duration": 0.036879,
     "end_time": "2022-05-07T10:21:19.554563",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.517684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6919, 4000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c699ef6",
   "metadata": {
    "papermill": {
     "duration": 0.029446,
     "end_time": "2022-05-07T10:21:19.613067",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.583621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a0d6c",
   "metadata": {
    "papermill": {
     "duration": 0.02883,
     "end_time": "2022-05-07T10:21:19.670989",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.642159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Choosing number of nodes and layers\n",
    "There is no final, definite, rule of thumb on how many nodes (or hidden neurons) or how many layers one should choose, and very often a trial and error approach will give you the best results for your individual problem. Generally, 2 layers have shown to be enough to detect more complex features. More layers can be better but also harder to train. As a general rule of thumb — 1 hidden layer work with simple problems, like this, and two are enough to find reasonably complex features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7863df7",
   "metadata": {
    "papermill": {
     "duration": 0.029026,
     "end_time": "2022-05-07T10:21:19.729164",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.700138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Choosing additional hyperparameters\n",
    "\n",
    "- **Dropout**: Every LSTM layer should be accompanied by a Dropout layer. This layer will help to prevent overfitting by ignoring randomly selected neurons during training, and hence reduces the sensitivity to the specific weights of individual neurons. 20% is often used as a good compromise between retaining model accuracy and preventing overfitting.\n",
    "- **Activation layer**: Technically, this can be included into the density layer, but there is a reason to split this apart. While not relevant here, splitting the density layer and the activation layer makes it possible to retrieve the reduced output of the density layer of the model. Which activation function to use is, again, depending on the application. Sigmoid function is used for binary classification problems. \n",
    "- **Loss function**: Loss function and activation function are often chosen together. Cross-entropy or more precise the binary cross-entropy, is the preferred loss function since we are faced with a binary classification problem. \n",
    "- **Optimizer**: For choosing the optimizer, adaptive moment estimation, short _Adam_, has been shown to work well in most practical applications and works well with only little changes in the hyperparameters. \n",
    "- **Metric**: In many cases, judging the models’ performance from an overall _accuracy_ point of view will be the option easiest to interpret as well as sufficient in resulting model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b215b1cd",
   "metadata": {
    "papermill": {
     "duration": 0.028932,
     "end_time": "2022-05-07T10:21:19.787258",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.758326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Simple LSTM with embedding layer:\n",
    "\n",
    "https://mmuratarat.github.io/2019-06-12/embeddings-with-numeric-variables-Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ddc0c",
   "metadata": {
    "papermill": {
     "duration": 0.028733,
     "end_time": "2022-05-07T10:21:19.845077",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.816344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are three parameters to the embedding layer:\n",
    "- **input_dim** : Size of the vocabulary\n",
    "- **output_dim** : Embedding size. Output length of the vector for each word\n",
    "- **input_length** : Maximum length of a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f74359a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:19.909500Z",
     "iopub.status.busy": "2022-05-07T10:21:19.908613Z",
     "iopub.status.idle": "2022-05-07T10:21:19.910697Z",
     "shell.execute_reply": "2022-05-07T10:21:19.911115Z"
    },
    "papermill": {
     "duration": 0.036214,
     "end_time": "2022-05-07T10:21:19.911254",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.875040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = 5 # input dimension: 4 bases + padding \n",
    "\n",
    "embedding_size = min(np.ceil((input_dim)/2), 50)\n",
    "embedding_size = int(embedding_size)\n",
    "\n",
    "output_dim = embedding_size\n",
    "input_length = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "971280a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T10:21:19.978438Z",
     "iopub.status.busy": "2022-05-07T10:21:19.977926Z",
     "iopub.status.idle": "2022-05-07T12:04:18.254816Z",
     "shell.execute_reply": "2022-05-07T12:04:18.255527Z"
    },
    "papermill": {
     "duration": 6178.315436,
     "end_time": "2022-05-07T12:04:18.255740",
     "exception": false,
     "start_time": "2022-05-07T10:21:19.940304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 10:21:20.062169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:20.172961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:20.173715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:20.174887: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-07 10:21:20.176212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:20.176918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:20.177562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:22.103934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:22.104732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:22.105424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 10:21:22.106017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-05-07 10:21:22.809066: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 10:21:25.239522: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 16s 287ms/step - loss: 0.6966 - acc: 0.5424 - val_loss: 0.6903 - val_acc: 0.4884\n",
      "Epoch 2/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.6861 - acc: 0.5380 - val_loss: 0.6828 - val_acc: 0.5455\n",
      "Epoch 3/500\n",
      "44/44 [==============================] - 12s 276ms/step - loss: 0.6852 - acc: 0.6126 - val_loss: 0.6568 - val_acc: 0.6163\n",
      "Epoch 4/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6552 - acc: 0.6343 - val_loss: 0.6740 - val_acc: 0.5506\n",
      "Epoch 5/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6540 - acc: 0.6226 - val_loss: 0.5932 - val_acc: 0.7030\n",
      "Epoch 6/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.6373 - acc: 0.6482 - val_loss: 0.5824 - val_acc: 0.7355\n",
      "Epoch 7/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.6251 - acc: 0.6690 - val_loss: 0.5650 - val_acc: 0.7645\n",
      "Epoch 8/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.6337 - acc: 0.6508 - val_loss: 0.6410 - val_acc: 0.6293\n",
      "Epoch 9/500\n",
      "44/44 [==============================] - 12s 278ms/step - loss: 0.6243 - acc: 0.6264 - val_loss: 0.6609 - val_acc: 0.6293\n",
      "Epoch 10/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.7286 - acc: 0.5982 - val_loss: 0.6926 - val_acc: 0.5224\n",
      "Epoch 11/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.6880 - acc: 0.5310 - val_loss: 0.6955 - val_acc: 0.5145\n",
      "Epoch 12/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6710 - acc: 0.5928 - val_loss: 0.5969 - val_acc: 0.6980\n",
      "Epoch 13/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.6754 - acc: 0.6020 - val_loss: 0.6240 - val_acc: 0.6640\n",
      "Epoch 14/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.6239 - acc: 0.6802 - val_loss: 0.6098 - val_acc: 0.6662\n",
      "Epoch 15/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6006 - acc: 0.6972 - val_loss: 0.6317 - val_acc: 0.6734\n",
      "Epoch 16/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6131 - acc: 0.6717 - val_loss: 0.6398 - val_acc: 0.6120\n",
      "Epoch 17/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.6571 - acc: 0.6829 - val_loss: 0.5789 - val_acc: 0.6893\n",
      "Epoch 18/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.5816 - acc: 0.7154 - val_loss: 0.5376 - val_acc: 0.7746\n",
      "Epoch 19/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.6043 - acc: 0.7014 - val_loss: 0.6669 - val_acc: 0.6091\n",
      "Epoch 20/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6383 - acc: 0.6591 - val_loss: 0.5631 - val_acc: 0.6929\n",
      "Epoch 21/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6001 - acc: 0.6869 - val_loss: 0.6195 - val_acc: 0.6835\n",
      "Epoch 22/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.5779 - acc: 0.7055 - val_loss: 0.7092 - val_acc: 0.7168\n",
      "Epoch 23/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.6369 - acc: 0.6790 - val_loss: 0.6898 - val_acc: 0.5116\n",
      "Epoch 24/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6962 - acc: 0.5229 - val_loss: 0.6853 - val_acc: 0.5173\n",
      "Epoch 25/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.5960 - acc: 0.6835 - val_loss: 0.6832 - val_acc: 0.5094\n",
      "Epoch 26/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.6811 - acc: 0.5794 - val_loss: 0.5452 - val_acc: 0.7666\n",
      "Epoch 27/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.6108 - acc: 0.6847 - val_loss: 0.6277 - val_acc: 0.6662\n",
      "Epoch 28/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6440 - acc: 0.6137 - val_loss: 0.6777 - val_acc: 0.5990\n",
      "Epoch 29/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.6666 - acc: 0.6188 - val_loss: 0.8007 - val_acc: 0.5137\n",
      "Epoch 30/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.6386 - acc: 0.6302 - val_loss: 0.4972 - val_acc: 0.7623\n",
      "Epoch 31/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.5758 - acc: 0.7191 - val_loss: 0.5192 - val_acc: 0.7731\n",
      "Epoch 32/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.5870 - acc: 0.6941 - val_loss: 0.6248 - val_acc: 0.6727\n",
      "Epoch 33/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.5845 - acc: 0.6995 - val_loss: 0.6311 - val_acc: 0.6221\n",
      "Epoch 34/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.5749 - acc: 0.7033 - val_loss: 0.6165 - val_acc: 0.6575\n",
      "Epoch 35/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.5430 - acc: 0.7536 - val_loss: 0.4753 - val_acc: 0.8143\n",
      "Epoch 36/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4921 - acc: 0.7845 - val_loss: 0.6117 - val_acc: 0.7399\n",
      "Epoch 37/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4905 - acc: 0.7908 - val_loss: 0.8030 - val_acc: 0.5166\n",
      "Epoch 38/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.5262 - acc: 0.7442 - val_loss: 0.5160 - val_acc: 0.7601\n",
      "Epoch 39/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4877 - acc: 0.7933 - val_loss: 0.4902 - val_acc: 0.8071\n",
      "Epoch 40/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4627 - acc: 0.7946 - val_loss: 0.5724 - val_acc: 0.7103\n",
      "Epoch 41/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4764 - acc: 0.7904 - val_loss: 0.5457 - val_acc: 0.7594\n",
      "Epoch 42/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4951 - acc: 0.7803 - val_loss: 0.4651 - val_acc: 0.8165\n",
      "Epoch 43/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4810 - acc: 0.7911 - val_loss: 0.4547 - val_acc: 0.7999\n",
      "Epoch 44/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.5895 - acc: 0.7001 - val_loss: 0.5172 - val_acc: 0.7847\n",
      "Epoch 45/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.5314 - acc: 0.7588 - val_loss: 0.5197 - val_acc: 0.7738\n",
      "Epoch 46/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.5238 - acc: 0.7613 - val_loss: 0.5235 - val_acc: 0.7760\n",
      "Epoch 47/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.5127 - acc: 0.7642 - val_loss: 0.4599 - val_acc: 0.7897\n",
      "Epoch 48/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4857 - acc: 0.7879 - val_loss: 0.9381 - val_acc: 0.5217\n",
      "Epoch 49/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.7636 - acc: 0.5205 - val_loss: 0.5924 - val_acc: 0.6012\n",
      "Epoch 50/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.5002 - acc: 0.7510 - val_loss: 0.4912 - val_acc: 0.7897\n",
      "Epoch 51/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4788 - acc: 0.7758 - val_loss: 0.4817 - val_acc: 0.7970\n",
      "Epoch 52/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.4636 - acc: 0.7942 - val_loss: 0.4695 - val_acc: 0.8201\n",
      "Epoch 53/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4546 - acc: 0.8090 - val_loss: 0.5054 - val_acc: 0.7659\n",
      "Epoch 54/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.5295 - acc: 0.7456 - val_loss: 0.5961 - val_acc: 0.6647\n",
      "Epoch 55/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.4568 - acc: 0.7937 - val_loss: 0.4633 - val_acc: 0.8150\n",
      "Epoch 56/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4687 - acc: 0.7893 - val_loss: 0.4424 - val_acc: 0.8042\n",
      "Epoch 57/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4411 - acc: 0.8123 - val_loss: 1.1960 - val_acc: 0.5137\n",
      "Epoch 58/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.5922 - acc: 0.7133 - val_loss: 0.5831 - val_acc: 0.7218\n",
      "Epoch 59/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4885 - acc: 0.7662 - val_loss: 0.4303 - val_acc: 0.8042\n",
      "Epoch 60/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4537 - acc: 0.8020 - val_loss: 0.4750 - val_acc: 0.8020\n",
      "Epoch 61/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4947 - acc: 0.7635 - val_loss: 0.4458 - val_acc: 0.8194\n",
      "Epoch 62/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4367 - acc: 0.8090 - val_loss: 0.5239 - val_acc: 0.7645\n",
      "Epoch 63/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4323 - acc: 0.8186 - val_loss: 0.4099 - val_acc: 0.8223\n",
      "Epoch 64/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4565 - acc: 0.8074 - val_loss: 0.4798 - val_acc: 0.8179\n",
      "Epoch 65/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.4416 - acc: 0.8143 - val_loss: 0.3822 - val_acc: 0.8439\n",
      "Epoch 66/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4569 - acc: 0.7953 - val_loss: 0.4746 - val_acc: 0.7962\n",
      "Epoch 67/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4528 - acc: 0.8034 - val_loss: 0.3878 - val_acc: 0.8461\n",
      "Epoch 68/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4527 - acc: 0.8023 - val_loss: 0.3824 - val_acc: 0.8454\n",
      "Epoch 69/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4549 - acc: 0.8043 - val_loss: 0.5169 - val_acc: 0.7905\n",
      "Epoch 70/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4299 - acc: 0.8128 - val_loss: 0.3912 - val_acc: 0.8316\n",
      "Epoch 71/500\n",
      "44/44 [==============================] - 13s 287ms/step - loss: 0.4500 - acc: 0.8002 - val_loss: 0.6720 - val_acc: 0.5636\n",
      "Epoch 72/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.5199 - acc: 0.7389 - val_loss: 0.4181 - val_acc: 0.8273\n",
      "Epoch 73/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4362 - acc: 0.8215 - val_loss: 0.4605 - val_acc: 0.8165\n",
      "Epoch 74/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4592 - acc: 0.7951 - val_loss: 0.5228 - val_acc: 0.7601\n",
      "Epoch 75/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4384 - acc: 0.8126 - val_loss: 0.4187 - val_acc: 0.8403\n",
      "Epoch 76/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4344 - acc: 0.8192 - val_loss: 0.4877 - val_acc: 0.8056\n",
      "Epoch 77/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4255 - acc: 0.8161 - val_loss: 0.3902 - val_acc: 0.8468\n",
      "Epoch 78/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4149 - acc: 0.8217 - val_loss: 0.3801 - val_acc: 0.8461\n",
      "Epoch 79/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4024 - acc: 0.8354 - val_loss: 0.3710 - val_acc: 0.8483\n",
      "Epoch 80/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4250 - acc: 0.8222 - val_loss: 0.4017 - val_acc: 0.8512\n",
      "Epoch 81/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4058 - acc: 0.8320 - val_loss: 0.4517 - val_acc: 0.8006\n",
      "Epoch 82/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4133 - acc: 0.8237 - val_loss: 0.3742 - val_acc: 0.8555\n",
      "Epoch 83/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4225 - acc: 0.8235 - val_loss: 0.4790 - val_acc: 0.8027\n",
      "Epoch 84/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3984 - acc: 0.8332 - val_loss: 0.3703 - val_acc: 0.8569\n",
      "Epoch 85/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4108 - acc: 0.8278 - val_loss: 0.4995 - val_acc: 0.7825\n",
      "Epoch 86/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4017 - acc: 0.8336 - val_loss: 0.3854 - val_acc: 0.8454\n",
      "Epoch 87/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4204 - acc: 0.8269 - val_loss: 0.3983 - val_acc: 0.8454\n",
      "Epoch 88/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3990 - acc: 0.8360 - val_loss: 0.3793 - val_acc: 0.8605\n",
      "Epoch 89/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3966 - acc: 0.8374 - val_loss: 0.3777 - val_acc: 0.8454\n",
      "Epoch 90/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4076 - acc: 0.8246 - val_loss: 0.3851 - val_acc: 0.8490\n",
      "Epoch 91/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4045 - acc: 0.8327 - val_loss: 0.4373 - val_acc: 0.8186\n",
      "Epoch 92/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3896 - acc: 0.8399 - val_loss: 0.3895 - val_acc: 0.8374\n",
      "Epoch 93/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4065 - acc: 0.8287 - val_loss: 0.3856 - val_acc: 0.8273\n",
      "Epoch 94/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.3784 - acc: 0.8396 - val_loss: 0.3851 - val_acc: 0.8338\n",
      "Epoch 95/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3797 - acc: 0.8394 - val_loss: 0.5526 - val_acc: 0.7803\n",
      "Epoch 96/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.4147 - acc: 0.8305 - val_loss: 0.3747 - val_acc: 0.8569\n",
      "Epoch 97/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3810 - acc: 0.8450 - val_loss: 0.3717 - val_acc: 0.8324\n",
      "Epoch 98/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4906 - acc: 0.7678 - val_loss: 0.4591 - val_acc: 0.7840\n",
      "Epoch 99/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.4290 - acc: 0.8181 - val_loss: 0.4004 - val_acc: 0.8324\n",
      "Epoch 100/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3852 - acc: 0.8439 - val_loss: 0.3728 - val_acc: 0.8461\n",
      "Epoch 101/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.4000 - acc: 0.8327 - val_loss: 0.4812 - val_acc: 0.7608\n",
      "Epoch 102/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4449 - acc: 0.8128 - val_loss: 0.3850 - val_acc: 0.8324\n",
      "Epoch 103/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3810 - acc: 0.8416 - val_loss: 0.3713 - val_acc: 0.8447\n",
      "Epoch 104/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3913 - acc: 0.8392 - val_loss: 0.3786 - val_acc: 0.8439\n",
      "Epoch 105/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3947 - acc: 0.8349 - val_loss: 0.4120 - val_acc: 0.8410\n",
      "Epoch 106/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3961 - acc: 0.8356 - val_loss: 0.3807 - val_acc: 0.8519\n",
      "Epoch 107/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3940 - acc: 0.8332 - val_loss: 0.3748 - val_acc: 0.8533\n",
      "Epoch 108/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3837 - acc: 0.8410 - val_loss: 0.4189 - val_acc: 0.8403\n",
      "Epoch 109/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.3873 - acc: 0.8428 - val_loss: 0.4976 - val_acc: 0.7652\n",
      "Epoch 110/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3819 - acc: 0.8444 - val_loss: 0.4303 - val_acc: 0.7912\n",
      "Epoch 111/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3865 - acc: 0.8376 - val_loss: 0.3676 - val_acc: 0.8461\n",
      "Epoch 112/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.3779 - acc: 0.8426 - val_loss: 0.3649 - val_acc: 0.8627\n",
      "Epoch 113/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3749 - acc: 0.8396 - val_loss: 0.3463 - val_acc: 0.8548\n",
      "Epoch 114/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3664 - acc: 0.8481 - val_loss: 0.3429 - val_acc: 0.8656\n",
      "Epoch 115/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3670 - acc: 0.8434 - val_loss: 0.4623 - val_acc: 0.7789\n",
      "Epoch 116/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3711 - acc: 0.8477 - val_loss: 0.3846 - val_acc: 0.8382\n",
      "Epoch 117/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.4404 - acc: 0.7922 - val_loss: 0.4150 - val_acc: 0.8418\n",
      "Epoch 118/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3691 - acc: 0.8537 - val_loss: 0.3598 - val_acc: 0.8490\n",
      "Epoch 119/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3547 - acc: 0.8580 - val_loss: 0.6751 - val_acc: 0.7001\n",
      "Epoch 120/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3639 - acc: 0.8493 - val_loss: 0.4214 - val_acc: 0.8056\n",
      "Epoch 121/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3907 - acc: 0.8361 - val_loss: 0.3877 - val_acc: 0.8490\n",
      "Epoch 122/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3460 - acc: 0.8598 - val_loss: 0.3980 - val_acc: 0.8432\n",
      "Epoch 123/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3490 - acc: 0.8575 - val_loss: 0.4991 - val_acc: 0.7630\n",
      "Epoch 124/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3660 - acc: 0.8526 - val_loss: 0.3368 - val_acc: 0.8577\n",
      "Epoch 125/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3401 - acc: 0.8661 - val_loss: 0.3291 - val_acc: 0.8605\n",
      "Epoch 126/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3657 - acc: 0.8473 - val_loss: 0.4008 - val_acc: 0.8223\n",
      "Epoch 127/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3436 - acc: 0.8594 - val_loss: 0.3182 - val_acc: 0.8714\n",
      "Epoch 128/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.3363 - acc: 0.8600 - val_loss: 0.3339 - val_acc: 0.8685\n",
      "Epoch 129/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.3324 - acc: 0.8683 - val_loss: 0.3260 - val_acc: 0.8699\n",
      "Epoch 130/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3276 - acc: 0.8699 - val_loss: 0.2937 - val_acc: 0.8764\n",
      "Epoch 131/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3284 - acc: 0.8623 - val_loss: 0.2963 - val_acc: 0.8743\n",
      "Epoch 132/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3196 - acc: 0.8679 - val_loss: 0.3653 - val_acc: 0.8490\n",
      "Epoch 133/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.3111 - acc: 0.8746 - val_loss: 0.2700 - val_acc: 0.8981\n",
      "Epoch 134/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3184 - acc: 0.8743 - val_loss: 0.2760 - val_acc: 0.8960\n",
      "Epoch 135/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2842 - acc: 0.8873 - val_loss: 0.2813 - val_acc: 0.8952\n",
      "Epoch 136/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3037 - acc: 0.8824 - val_loss: 0.2556 - val_acc: 0.9075\n",
      "Epoch 137/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2883 - acc: 0.8847 - val_loss: 0.2491 - val_acc: 0.9046\n",
      "Epoch 138/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2797 - acc: 0.8833 - val_loss: 0.4210 - val_acc: 0.8186\n",
      "Epoch 139/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2757 - acc: 0.8902 - val_loss: 0.6222 - val_acc: 0.7738\n",
      "Epoch 140/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2854 - acc: 0.8891 - val_loss: 0.4692 - val_acc: 0.7912\n",
      "Epoch 141/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.2813 - acc: 0.8867 - val_loss: 0.3292 - val_acc: 0.8432\n",
      "Epoch 142/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2667 - acc: 0.8956 - val_loss: 0.3282 - val_acc: 0.8627\n",
      "Epoch 143/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2766 - acc: 0.8920 - val_loss: 0.2625 - val_acc: 0.9068\n",
      "Epoch 144/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2713 - acc: 0.8954 - val_loss: 0.2476 - val_acc: 0.9075\n",
      "Epoch 145/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2665 - acc: 0.8950 - val_loss: 0.3130 - val_acc: 0.8736\n",
      "Epoch 146/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2640 - acc: 0.8939 - val_loss: 0.2406 - val_acc: 0.9061\n",
      "Epoch 147/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2652 - acc: 0.8932 - val_loss: 0.2673 - val_acc: 0.8960\n",
      "Epoch 148/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2564 - acc: 0.9012 - val_loss: 0.2553 - val_acc: 0.9010\n",
      "Epoch 149/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2661 - acc: 0.8956 - val_loss: 0.2395 - val_acc: 0.9090\n",
      "Epoch 150/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2575 - acc: 0.8958 - val_loss: 0.3699 - val_acc: 0.8389\n",
      "Epoch 151/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2474 - acc: 0.9051 - val_loss: 0.4532 - val_acc: 0.7955\n",
      "Epoch 152/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2487 - acc: 0.9023 - val_loss: 0.2331 - val_acc: 0.9039\n",
      "Epoch 153/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2458 - acc: 0.9051 - val_loss: 0.2752 - val_acc: 0.8895\n",
      "Epoch 154/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2502 - acc: 0.9008 - val_loss: 0.2396 - val_acc: 0.9032\n",
      "Epoch 155/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2430 - acc: 0.9071 - val_loss: 0.2353 - val_acc: 0.9111\n",
      "Epoch 156/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2443 - acc: 0.9061 - val_loss: 0.2477 - val_acc: 0.9075\n",
      "Epoch 157/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2510 - acc: 0.9033 - val_loss: 0.2630 - val_acc: 0.8931\n",
      "Epoch 158/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2417 - acc: 0.9082 - val_loss: 0.4220 - val_acc: 0.8020\n",
      "Epoch 159/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2498 - acc: 0.9012 - val_loss: 0.2828 - val_acc: 0.8844\n",
      "Epoch 160/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2425 - acc: 0.9035 - val_loss: 0.2291 - val_acc: 0.9104\n",
      "Epoch 161/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2476 - acc: 0.9008 - val_loss: 0.2375 - val_acc: 0.9068\n",
      "Epoch 162/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2425 - acc: 0.9057 - val_loss: 0.2305 - val_acc: 0.9097\n",
      "Epoch 163/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2335 - acc: 0.9117 - val_loss: 0.3509 - val_acc: 0.8497\n",
      "Epoch 164/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.2332 - acc: 0.9095 - val_loss: 0.2577 - val_acc: 0.9046\n",
      "Epoch 165/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2348 - acc: 0.9109 - val_loss: 0.2273 - val_acc: 0.9126\n",
      "Epoch 166/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2310 - acc: 0.9113 - val_loss: 0.3469 - val_acc: 0.8627\n",
      "Epoch 167/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.2345 - acc: 0.9129 - val_loss: 0.2426 - val_acc: 0.9140\n",
      "Epoch 168/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2358 - acc: 0.9086 - val_loss: 0.2526 - val_acc: 0.9061\n",
      "Epoch 169/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.2297 - acc: 0.9144 - val_loss: 0.2431 - val_acc: 0.9162\n",
      "Epoch 170/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2227 - acc: 0.9167 - val_loss: 0.2373 - val_acc: 0.9097\n",
      "Epoch 171/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2166 - acc: 0.9198 - val_loss: 0.2340 - val_acc: 0.9082\n",
      "Epoch 172/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2315 - acc: 0.9086 - val_loss: 0.2490 - val_acc: 0.9104\n",
      "Epoch 173/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2404 - acc: 0.9113 - val_loss: 0.2399 - val_acc: 0.9046\n",
      "Epoch 174/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2188 - acc: 0.9154 - val_loss: 0.2499 - val_acc: 0.9075\n",
      "Epoch 175/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2328 - acc: 0.9113 - val_loss: 0.2681 - val_acc: 0.8996\n",
      "Epoch 176/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2235 - acc: 0.9133 - val_loss: 0.2572 - val_acc: 0.9082\n",
      "Epoch 177/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2182 - acc: 0.9144 - val_loss: 0.2500 - val_acc: 0.9017\n",
      "Epoch 178/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2350 - acc: 0.9075 - val_loss: 0.2274 - val_acc: 0.9097\n",
      "Epoch 179/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2331 - acc: 0.9131 - val_loss: 0.2668 - val_acc: 0.9025\n",
      "Epoch 180/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.2465 - acc: 0.9098 - val_loss: 0.2797 - val_acc: 0.9003\n",
      "Epoch 181/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.2239 - acc: 0.9162 - val_loss: 0.2323 - val_acc: 0.9090\n",
      "Epoch 182/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2118 - acc: 0.9191 - val_loss: 0.2336 - val_acc: 0.9155\n",
      "Epoch 183/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2648 - acc: 0.8983 - val_loss: 0.3613 - val_acc: 0.8562\n",
      "Epoch 184/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.3165 - acc: 0.8723 - val_loss: 0.3457 - val_acc: 0.8642\n",
      "Epoch 185/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.3149 - acc: 0.8701 - val_loss: 0.3212 - val_acc: 0.8728\n",
      "Epoch 186/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.3114 - acc: 0.8779 - val_loss: 0.4570 - val_acc: 0.8100\n",
      "Epoch 187/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2931 - acc: 0.8835 - val_loss: 0.3247 - val_acc: 0.8692\n",
      "Epoch 188/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2146 - acc: 0.9169 - val_loss: 0.3142 - val_acc: 0.8764\n",
      "Epoch 189/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2196 - acc: 0.9118 - val_loss: 0.2455 - val_acc: 0.9032\n",
      "Epoch 190/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2034 - acc: 0.9192 - val_loss: 0.4209 - val_acc: 0.8389\n",
      "Epoch 191/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2070 - acc: 0.9191 - val_loss: 0.2413 - val_acc: 0.9140\n",
      "Epoch 192/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2021 - acc: 0.9245 - val_loss: 0.3114 - val_acc: 0.8707\n",
      "Epoch 193/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2019 - acc: 0.9221 - val_loss: 0.4848 - val_acc: 0.8158\n",
      "Epoch 194/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.2236 - acc: 0.9138 - val_loss: 0.2230 - val_acc: 0.9147\n",
      "Epoch 195/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2046 - acc: 0.9201 - val_loss: 0.2421 - val_acc: 0.9082\n",
      "Epoch 196/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2089 - acc: 0.9194 - val_loss: 0.2301 - val_acc: 0.9090\n",
      "Epoch 197/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1979 - acc: 0.9221 - val_loss: 0.2339 - val_acc: 0.9075\n",
      "Epoch 198/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1967 - acc: 0.9203 - val_loss: 0.2541 - val_acc: 0.9126\n",
      "Epoch 199/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1991 - acc: 0.9230 - val_loss: 0.2399 - val_acc: 0.9140\n",
      "Epoch 200/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1904 - acc: 0.9274 - val_loss: 0.2261 - val_acc: 0.9191\n",
      "Epoch 201/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.2312 - acc: 0.9126 - val_loss: 0.2248 - val_acc: 0.9205\n",
      "Epoch 202/500\n",
      "44/44 [==============================] - 12s 278ms/step - loss: 0.2007 - acc: 0.9281 - val_loss: 0.2189 - val_acc: 0.9205\n",
      "Epoch 203/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1982 - acc: 0.9259 - val_loss: 0.2266 - val_acc: 0.9147\n",
      "Epoch 204/500\n",
      "44/44 [==============================] - 12s 284ms/step - loss: 0.1882 - acc: 0.9304 - val_loss: 0.2923 - val_acc: 0.8837\n",
      "Epoch 205/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1915 - acc: 0.9313 - val_loss: 0.2717 - val_acc: 0.8952\n",
      "Epoch 206/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1751 - acc: 0.9326 - val_loss: 0.2637 - val_acc: 0.9046\n",
      "Epoch 207/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1927 - acc: 0.9279 - val_loss: 0.2230 - val_acc: 0.9169\n",
      "Epoch 208/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1745 - acc: 0.9368 - val_loss: 0.2285 - val_acc: 0.9155\n",
      "Epoch 209/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1707 - acc: 0.9328 - val_loss: 0.2307 - val_acc: 0.9147\n",
      "Epoch 210/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2024 - acc: 0.9288 - val_loss: 0.3221 - val_acc: 0.8952\n",
      "Epoch 211/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1743 - acc: 0.9308 - val_loss: 0.2201 - val_acc: 0.9191\n",
      "Epoch 212/500\n",
      "44/44 [==============================] - 12s 284ms/step - loss: 0.1629 - acc: 0.9368 - val_loss: 0.3048 - val_acc: 0.8996\n",
      "Epoch 213/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1629 - acc: 0.9398 - val_loss: 0.3195 - val_acc: 0.9017\n",
      "Epoch 214/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.2241 - acc: 0.9135 - val_loss: 0.2506 - val_acc: 0.9046\n",
      "Epoch 215/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1675 - acc: 0.9364 - val_loss: 0.2613 - val_acc: 0.9046\n",
      "Epoch 216/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1667 - acc: 0.9384 - val_loss: 0.2765 - val_acc: 0.9032\n",
      "Epoch 217/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1606 - acc: 0.9440 - val_loss: 0.2470 - val_acc: 0.9133\n",
      "Epoch 218/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1723 - acc: 0.9369 - val_loss: 0.2365 - val_acc: 0.9068\n",
      "Epoch 219/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1515 - acc: 0.9442 - val_loss: 0.2357 - val_acc: 0.9097\n",
      "Epoch 220/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1676 - acc: 0.9380 - val_loss: 0.2836 - val_acc: 0.8988\n",
      "Epoch 221/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2182 - acc: 0.9221 - val_loss: 0.2583 - val_acc: 0.9053\n",
      "Epoch 222/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1740 - acc: 0.9360 - val_loss: 0.2403 - val_acc: 0.9118\n",
      "Epoch 223/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1474 - acc: 0.9465 - val_loss: 0.2431 - val_acc: 0.9097\n",
      "Epoch 224/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1521 - acc: 0.9397 - val_loss: 0.2507 - val_acc: 0.9082\n",
      "Epoch 225/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.1449 - acc: 0.9463 - val_loss: 0.2622 - val_acc: 0.9061\n",
      "Epoch 226/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2842 - acc: 0.8916 - val_loss: 0.3546 - val_acc: 0.8569\n",
      "Epoch 227/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.2376 - acc: 0.9053 - val_loss: 0.2344 - val_acc: 0.9176\n",
      "Epoch 228/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1551 - acc: 0.9438 - val_loss: 0.2350 - val_acc: 0.9126\n",
      "Epoch 229/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1476 - acc: 0.9453 - val_loss: 0.2330 - val_acc: 0.9075\n",
      "Epoch 230/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1350 - acc: 0.9543 - val_loss: 0.2544 - val_acc: 0.9111\n",
      "Epoch 231/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1385 - acc: 0.9525 - val_loss: 0.2868 - val_acc: 0.8960\n",
      "Epoch 232/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1296 - acc: 0.9491 - val_loss: 0.2513 - val_acc: 0.9104\n",
      "Epoch 233/500\n",
      "44/44 [==============================] - 13s 286ms/step - loss: 0.1584 - acc: 0.9416 - val_loss: 0.2648 - val_acc: 0.9097\n",
      "Epoch 234/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1290 - acc: 0.9532 - val_loss: 0.2557 - val_acc: 0.9061\n",
      "Epoch 235/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1601 - acc: 0.9404 - val_loss: 0.2710 - val_acc: 0.9010\n",
      "Epoch 236/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1472 - acc: 0.9436 - val_loss: 0.2763 - val_acc: 0.9090\n",
      "Epoch 237/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1401 - acc: 0.9516 - val_loss: 0.2684 - val_acc: 0.9082\n",
      "Epoch 238/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1251 - acc: 0.9545 - val_loss: 0.3851 - val_acc: 0.8743\n",
      "Epoch 239/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1568 - acc: 0.9420 - val_loss: 0.2420 - val_acc: 0.9205\n",
      "Epoch 240/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1166 - acc: 0.9583 - val_loss: 0.3027 - val_acc: 0.8974\n",
      "Epoch 241/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1309 - acc: 0.9519 - val_loss: 0.2429 - val_acc: 0.9176\n",
      "Epoch 242/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1403 - acc: 0.9476 - val_loss: 0.2961 - val_acc: 0.9046\n",
      "Epoch 243/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1237 - acc: 0.9548 - val_loss: 0.2530 - val_acc: 0.9118\n",
      "Epoch 244/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1272 - acc: 0.9536 - val_loss: 0.2810 - val_acc: 0.9097\n",
      "Epoch 245/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.1336 - acc: 0.9503 - val_loss: 0.2582 - val_acc: 0.9104\n",
      "Epoch 246/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1149 - acc: 0.9581 - val_loss: 0.2601 - val_acc: 0.9155\n",
      "Epoch 247/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1083 - acc: 0.9613 - val_loss: 0.2616 - val_acc: 0.9147\n",
      "Epoch 248/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1271 - acc: 0.9566 - val_loss: 0.2551 - val_acc: 0.9162\n",
      "Epoch 249/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1864 - acc: 0.9393 - val_loss: 0.2639 - val_acc: 0.9075\n",
      "Epoch 250/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1004 - acc: 0.9650 - val_loss: 0.2608 - val_acc: 0.9118\n",
      "Epoch 251/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0919 - acc: 0.9664 - val_loss: 0.2750 - val_acc: 0.9097\n",
      "Epoch 252/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1013 - acc: 0.9639 - val_loss: 0.2900 - val_acc: 0.9097\n",
      "Epoch 253/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1134 - acc: 0.9610 - val_loss: 0.2788 - val_acc: 0.9155\n",
      "Epoch 254/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1131 - acc: 0.9548 - val_loss: 0.3321 - val_acc: 0.8974\n",
      "Epoch 255/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1346 - acc: 0.9491 - val_loss: 0.2571 - val_acc: 0.9082\n",
      "Epoch 256/500\n",
      "44/44 [==============================] - 13s 285ms/step - loss: 0.1200 - acc: 0.9548 - val_loss: 0.2703 - val_acc: 0.9118\n",
      "Epoch 257/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1002 - acc: 0.9603 - val_loss: 0.2707 - val_acc: 0.9162\n",
      "Epoch 258/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0890 - acc: 0.9668 - val_loss: 0.2917 - val_acc: 0.9061\n",
      "Epoch 259/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0901 - acc: 0.9659 - val_loss: 0.2803 - val_acc: 0.8988\n",
      "Epoch 260/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0854 - acc: 0.9689 - val_loss: 0.3082 - val_acc: 0.9010\n",
      "Epoch 261/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0824 - acc: 0.9715 - val_loss: 0.3077 - val_acc: 0.9126\n",
      "Epoch 262/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1020 - acc: 0.9648 - val_loss: 0.2853 - val_acc: 0.9133\n",
      "Epoch 263/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1141 - acc: 0.9617 - val_loss: 0.2865 - val_acc: 0.9191\n",
      "Epoch 264/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1602 - acc: 0.9489 - val_loss: 0.3080 - val_acc: 0.9082\n",
      "Epoch 265/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.1005 - acc: 0.9673 - val_loss: 0.2636 - val_acc: 0.9184\n",
      "Epoch 266/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.1058 - acc: 0.9624 - val_loss: 0.2818 - val_acc: 0.9097\n",
      "Epoch 267/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0917 - acc: 0.9671 - val_loss: 0.2907 - val_acc: 0.8981\n",
      "Epoch 268/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0812 - acc: 0.9742 - val_loss: 0.2720 - val_acc: 0.9198\n",
      "Epoch 269/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0769 - acc: 0.9729 - val_loss: 0.2734 - val_acc: 0.9191\n",
      "Epoch 270/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.1156 - acc: 0.9593 - val_loss: 0.3367 - val_acc: 0.8923\n",
      "Epoch 271/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0735 - acc: 0.9733 - val_loss: 0.2907 - val_acc: 0.9162\n",
      "Epoch 272/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.0665 - acc: 0.9752 - val_loss: 0.2792 - val_acc: 0.9126\n",
      "Epoch 273/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0751 - acc: 0.9749 - val_loss: 0.3696 - val_acc: 0.8909\n",
      "Epoch 274/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0835 - acc: 0.9722 - val_loss: 0.2910 - val_acc: 0.9111\n",
      "Epoch 275/500\n",
      "44/44 [==============================] - 12s 284ms/step - loss: 0.0885 - acc: 0.9691 - val_loss: 0.2939 - val_acc: 0.9046\n",
      "Epoch 276/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0566 - acc: 0.9810 - val_loss: 0.3282 - val_acc: 0.9111\n",
      "Epoch 277/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0816 - acc: 0.9718 - val_loss: 0.2834 - val_acc: 0.9198\n",
      "Epoch 278/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0608 - acc: 0.9807 - val_loss: 0.3596 - val_acc: 0.9003\n",
      "Epoch 279/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0664 - acc: 0.9767 - val_loss: 0.3285 - val_acc: 0.9133\n",
      "Epoch 280/500\n",
      "44/44 [==============================] - 13s 287ms/step - loss: 0.0582 - acc: 0.9821 - val_loss: 0.2944 - val_acc: 0.9241\n",
      "Epoch 281/500\n",
      "44/44 [==============================] - 13s 285ms/step - loss: 0.0888 - acc: 0.9682 - val_loss: 0.3082 - val_acc: 0.9176\n",
      "Epoch 282/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0897 - acc: 0.9731 - val_loss: 0.2864 - val_acc: 0.9111\n",
      "Epoch 283/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0730 - acc: 0.9749 - val_loss: 0.3162 - val_acc: 0.9075\n",
      "Epoch 284/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0758 - acc: 0.9752 - val_loss: 0.3078 - val_acc: 0.9126\n",
      "Epoch 285/500\n",
      "44/44 [==============================] - 13s 288ms/step - loss: 0.0829 - acc: 0.9742 - val_loss: 0.3327 - val_acc: 0.9025\n",
      "Epoch 286/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0754 - acc: 0.9733 - val_loss: 0.3635 - val_acc: 0.9017\n",
      "Epoch 287/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0535 - acc: 0.9808 - val_loss: 0.3594 - val_acc: 0.9104\n",
      "Epoch 288/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0640 - acc: 0.9787 - val_loss: 0.2948 - val_acc: 0.9133\n",
      "Epoch 289/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0562 - acc: 0.9839 - val_loss: 0.3477 - val_acc: 0.9032\n",
      "Epoch 290/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0495 - acc: 0.9845 - val_loss: 0.3408 - val_acc: 0.9155\n",
      "Epoch 291/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.0541 - acc: 0.9837 - val_loss: 0.3176 - val_acc: 0.9032\n",
      "Epoch 292/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0437 - acc: 0.9866 - val_loss: 0.3301 - val_acc: 0.9147\n",
      "Epoch 293/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0817 - acc: 0.9752 - val_loss: 0.3348 - val_acc: 0.9118\n",
      "Epoch 294/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0615 - acc: 0.9790 - val_loss: 0.2925 - val_acc: 0.9147\n",
      "Epoch 295/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0537 - acc: 0.9830 - val_loss: 0.3348 - val_acc: 0.9169\n",
      "Epoch 296/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0573 - acc: 0.9810 - val_loss: 0.3315 - val_acc: 0.9133\n",
      "Epoch 297/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0420 - acc: 0.9846 - val_loss: 0.3431 - val_acc: 0.9140\n",
      "Epoch 298/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0329 - acc: 0.9895 - val_loss: 0.3623 - val_acc: 0.9140\n",
      "Epoch 299/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0548 - acc: 0.9848 - val_loss: 0.3579 - val_acc: 0.9162\n",
      "Epoch 300/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0677 - acc: 0.9769 - val_loss: 0.3394 - val_acc: 0.9010\n",
      "Epoch 301/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0406 - acc: 0.9875 - val_loss: 0.3530 - val_acc: 0.9118\n",
      "Epoch 302/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0697 - acc: 0.9776 - val_loss: 0.4062 - val_acc: 0.8822\n",
      "Epoch 303/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0525 - acc: 0.9827 - val_loss: 0.3868 - val_acc: 0.9097\n",
      "Epoch 304/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0365 - acc: 0.9875 - val_loss: 0.3342 - val_acc: 0.9198\n",
      "Epoch 305/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0358 - acc: 0.9899 - val_loss: 0.3890 - val_acc: 0.8988\n",
      "Epoch 306/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0373 - acc: 0.9892 - val_loss: 0.3631 - val_acc: 0.9133\n",
      "Epoch 307/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0427 - acc: 0.9861 - val_loss: 0.6523 - val_acc: 0.8620\n",
      "Epoch 308/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0648 - acc: 0.9778 - val_loss: 0.3736 - val_acc: 0.9097\n",
      "Epoch 309/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0492 - acc: 0.9852 - val_loss: 0.3538 - val_acc: 0.9191\n",
      "Epoch 310/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0287 - acc: 0.9922 - val_loss: 0.3569 - val_acc: 0.9126\n",
      "Epoch 311/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0597 - acc: 0.9805 - val_loss: 0.4017 - val_acc: 0.9075\n",
      "Epoch 312/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0421 - acc: 0.9877 - val_loss: 0.3629 - val_acc: 0.9147\n",
      "Epoch 313/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0308 - acc: 0.9908 - val_loss: 0.4362 - val_acc: 0.9061\n",
      "Epoch 314/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0449 - acc: 0.9879 - val_loss: 0.7590 - val_acc: 0.8360\n",
      "Epoch 315/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0408 - acc: 0.9884 - val_loss: 0.3499 - val_acc: 0.9111\n",
      "Epoch 316/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0351 - acc: 0.9899 - val_loss: 0.3497 - val_acc: 0.9090\n",
      "Epoch 317/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0396 - acc: 0.9901 - val_loss: 0.3536 - val_acc: 0.9212\n",
      "Epoch 318/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0217 - acc: 0.9939 - val_loss: 0.3552 - val_acc: 0.9118\n",
      "Epoch 319/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0297 - acc: 0.9917 - val_loss: 0.3663 - val_acc: 0.9184\n",
      "Epoch 320/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0307 - acc: 0.9908 - val_loss: 0.3568 - val_acc: 0.9140\n",
      "Epoch 321/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0313 - acc: 0.9917 - val_loss: 0.3798 - val_acc: 0.9118\n",
      "Epoch 322/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0231 - acc: 0.9937 - val_loss: 0.4119 - val_acc: 0.9053\n",
      "Epoch 323/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.4814 - val_acc: 0.9003\n",
      "Epoch 324/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0335 - acc: 0.9908 - val_loss: 0.3835 - val_acc: 0.9176\n",
      "Epoch 325/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0552 - acc: 0.9868 - val_loss: 0.3542 - val_acc: 0.9097\n",
      "Epoch 326/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0431 - acc: 0.9850 - val_loss: 0.3784 - val_acc: 0.9184\n",
      "Epoch 327/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0324 - acc: 0.9888 - val_loss: 0.4245 - val_acc: 0.9126\n",
      "Epoch 328/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0318 - acc: 0.9899 - val_loss: 0.3935 - val_acc: 0.9155\n",
      "Epoch 329/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0157 - acc: 0.9946 - val_loss: 0.4277 - val_acc: 0.9053\n",
      "Epoch 330/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0472 - acc: 0.9892 - val_loss: 0.4146 - val_acc: 0.9205\n",
      "Epoch 331/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0178 - acc: 0.9958 - val_loss: 0.4164 - val_acc: 0.9162\n",
      "Epoch 332/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0230 - acc: 0.9937 - val_loss: 0.4627 - val_acc: 0.9039\n",
      "Epoch 333/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0440 - acc: 0.9870 - val_loss: 0.4336 - val_acc: 0.9155\n",
      "Epoch 334/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0209 - acc: 0.9939 - val_loss: 0.4566 - val_acc: 0.9017\n",
      "Epoch 335/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0384 - acc: 0.9890 - val_loss: 0.4420 - val_acc: 0.9104\n",
      "Epoch 336/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0331 - acc: 0.9904 - val_loss: 0.4222 - val_acc: 0.9147\n",
      "Epoch 337/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0259 - acc: 0.9928 - val_loss: 0.3889 - val_acc: 0.9184\n",
      "Epoch 338/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0355 - acc: 0.9904 - val_loss: 0.4015 - val_acc: 0.9162\n",
      "Epoch 339/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0314 - acc: 0.9940 - val_loss: 0.5787 - val_acc: 0.8996\n",
      "Epoch 340/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0449 - acc: 0.9870 - val_loss: 0.4290 - val_acc: 0.9039\n",
      "Epoch 341/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.0230 - acc: 0.9922 - val_loss: 0.4166 - val_acc: 0.9198\n",
      "Epoch 342/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0310 - acc: 0.9897 - val_loss: 0.4376 - val_acc: 0.9053\n",
      "Epoch 343/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0581 - acc: 0.9836 - val_loss: 0.4019 - val_acc: 0.9263\n",
      "Epoch 344/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0342 - acc: 0.9886 - val_loss: 0.4044 - val_acc: 0.9118\n",
      "Epoch 345/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0223 - acc: 0.9940 - val_loss: 0.4273 - val_acc: 0.9104\n",
      "Epoch 346/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0152 - acc: 0.9960 - val_loss: 0.3990 - val_acc: 0.9191\n",
      "Epoch 347/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0262 - acc: 0.9931 - val_loss: 0.4262 - val_acc: 0.9162\n",
      "Epoch 348/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.2092 - acc: 0.9541 - val_loss: 0.4663 - val_acc: 0.9104\n",
      "Epoch 349/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0677 - acc: 0.9796 - val_loss: 0.4071 - val_acc: 0.9220\n",
      "Epoch 350/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0373 - acc: 0.9906 - val_loss: 0.4037 - val_acc: 0.9090\n",
      "Epoch 351/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0237 - acc: 0.9931 - val_loss: 0.4023 - val_acc: 0.9184\n",
      "Epoch 352/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0293 - acc: 0.9926 - val_loss: 0.4231 - val_acc: 0.9234\n",
      "Epoch 353/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0211 - acc: 0.9939 - val_loss: 0.4095 - val_acc: 0.9176\n",
      "Epoch 354/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0244 - acc: 0.9940 - val_loss: 0.4015 - val_acc: 0.9176\n",
      "Epoch 355/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0153 - acc: 0.9962 - val_loss: 0.4217 - val_acc: 0.9212\n",
      "Epoch 356/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0550 - acc: 0.9872 - val_loss: 0.4040 - val_acc: 0.9090\n",
      "Epoch 357/500\n",
      "44/44 [==============================] - 12s 284ms/step - loss: 0.0141 - acc: 0.9966 - val_loss: 0.4219 - val_acc: 0.9220\n",
      "Epoch 358/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0311 - acc: 0.9928 - val_loss: 0.4185 - val_acc: 0.9169\n",
      "Epoch 359/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0220 - acc: 0.9948 - val_loss: 0.4363 - val_acc: 0.9147\n",
      "Epoch 360/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0151 - acc: 0.9964 - val_loss: 0.4613 - val_acc: 0.9140\n",
      "Epoch 361/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0185 - acc: 0.9948 - val_loss: 0.6275 - val_acc: 0.8945\n",
      "Epoch 362/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0231 - acc: 0.9931 - val_loss: 0.4980 - val_acc: 0.9097\n",
      "Epoch 363/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0250 - acc: 0.9930 - val_loss: 0.4060 - val_acc: 0.9270\n",
      "Epoch 364/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0171 - acc: 0.9955 - val_loss: 0.4495 - val_acc: 0.9198\n",
      "Epoch 365/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.4693 - val_acc: 0.9104\n",
      "Epoch 366/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0258 - acc: 0.9935 - val_loss: 0.5334 - val_acc: 0.9068\n",
      "Epoch 367/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0308 - acc: 0.9919 - val_loss: 0.4232 - val_acc: 0.9126\n",
      "Epoch 368/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0400 - acc: 0.9870 - val_loss: 0.4515 - val_acc: 0.9198\n",
      "Epoch 369/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0546 - acc: 0.9874 - val_loss: 0.4643 - val_acc: 0.9162\n",
      "Epoch 370/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0347 - acc: 0.9892 - val_loss: 0.4781 - val_acc: 0.9169\n",
      "Epoch 371/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0200 - acc: 0.9940 - val_loss: 0.4471 - val_acc: 0.9140\n",
      "Epoch 372/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0165 - acc: 0.9948 - val_loss: 0.4354 - val_acc: 0.9198\n",
      "Epoch 373/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0226 - acc: 0.9939 - val_loss: 0.4407 - val_acc: 0.9104\n",
      "Epoch 374/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0129 - acc: 0.9955 - val_loss: 0.4407 - val_acc: 0.9241\n",
      "Epoch 375/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0138 - acc: 0.9960 - val_loss: 0.4409 - val_acc: 0.9212\n",
      "Epoch 376/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0434 - acc: 0.9902 - val_loss: 0.4226 - val_acc: 0.9205\n",
      "Epoch 377/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0171 - acc: 0.9962 - val_loss: 0.4348 - val_acc: 0.9191\n",
      "Epoch 378/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0184 - acc: 0.9951 - val_loss: 0.4485 - val_acc: 0.9147\n",
      "Epoch 379/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0197 - acc: 0.9948 - val_loss: 0.4368 - val_acc: 0.9205\n",
      "Epoch 380/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0282 - acc: 0.9933 - val_loss: 0.4330 - val_acc: 0.9191\n",
      "Epoch 381/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0161 - acc: 0.9958 - val_loss: 0.5104 - val_acc: 0.9212\n",
      "Epoch 382/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0204 - acc: 0.9951 - val_loss: 0.5095 - val_acc: 0.9126\n",
      "Epoch 383/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0375 - acc: 0.9910 - val_loss: 0.4743 - val_acc: 0.9184\n",
      "Epoch 384/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0186 - acc: 0.9946 - val_loss: 0.4585 - val_acc: 0.9111\n",
      "Epoch 385/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0231 - acc: 0.9928 - val_loss: 0.4513 - val_acc: 0.9140\n",
      "Epoch 386/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0136 - acc: 0.9955 - val_loss: 0.4517 - val_acc: 0.9075\n",
      "Epoch 387/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0177 - acc: 0.9949 - val_loss: 0.4332 - val_acc: 0.9256\n",
      "Epoch 388/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0511 - acc: 0.9897 - val_loss: 0.4245 - val_acc: 0.9227\n",
      "Epoch 389/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0088 - acc: 0.9977 - val_loss: 0.4111 - val_acc: 0.9169\n",
      "Epoch 390/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0134 - acc: 0.9967 - val_loss: 0.4871 - val_acc: 0.9234\n",
      "Epoch 391/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.4657 - val_acc: 0.9256\n",
      "Epoch 392/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0342 - acc: 0.9922 - val_loss: 0.4245 - val_acc: 0.9198\n",
      "Epoch 393/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.4596 - val_acc: 0.9220\n",
      "Epoch 394/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0227 - acc: 0.9930 - val_loss: 0.4634 - val_acc: 0.9169\n",
      "Epoch 395/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0148 - acc: 0.9942 - val_loss: 0.4742 - val_acc: 0.9133\n",
      "Epoch 396/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0131 - acc: 0.9967 - val_loss: 0.5012 - val_acc: 0.9155\n",
      "Epoch 397/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0099 - acc: 0.9973 - val_loss: 0.4648 - val_acc: 0.9162\n",
      "Epoch 398/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0159 - acc: 0.9958 - val_loss: 0.4936 - val_acc: 0.9212\n",
      "Epoch 399/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0258 - acc: 0.9933 - val_loss: 0.4380 - val_acc: 0.9263\n",
      "Epoch 400/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0208 - acc: 0.9955 - val_loss: 0.4904 - val_acc: 0.9227\n",
      "Epoch 401/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.5983 - val_acc: 0.8981\n",
      "Epoch 402/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.4868 - val_acc: 0.9155\n",
      "Epoch 403/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.5148 - val_acc: 0.9147\n",
      "Epoch 404/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0293 - acc: 0.9915 - val_loss: 0.4800 - val_acc: 0.9176\n",
      "Epoch 405/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.5267 - val_acc: 0.9184\n",
      "Epoch 406/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.5205 - val_acc: 0.9155\n",
      "Epoch 407/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.4917 - val_acc: 0.9133\n",
      "Epoch 408/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.0067 - acc: 0.9977 - val_loss: 0.5710 - val_acc: 0.9140\n",
      "Epoch 409/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.5314 - val_acc: 0.9061\n",
      "Epoch 410/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0144 - acc: 0.9955 - val_loss: 0.5363 - val_acc: 0.9118\n",
      "Epoch 411/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0316 - acc: 0.9926 - val_loss: 0.4835 - val_acc: 0.9155\n",
      "Epoch 412/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0137 - acc: 0.9973 - val_loss: 0.4938 - val_acc: 0.9104\n",
      "Epoch 413/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.4919 - val_acc: 0.9147\n",
      "Epoch 414/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0108 - acc: 0.9962 - val_loss: 0.5445 - val_acc: 0.9169\n",
      "Epoch 415/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0179 - acc: 0.9955 - val_loss: 0.5105 - val_acc: 0.9191\n",
      "Epoch 416/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0156 - acc: 0.9962 - val_loss: 0.7070 - val_acc: 0.8837\n",
      "Epoch 417/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0161 - acc: 0.9953 - val_loss: 0.5132 - val_acc: 0.9147\n",
      "Epoch 418/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.5209 - val_acc: 0.9155\n",
      "Epoch 419/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.0106 - acc: 0.9977 - val_loss: 0.4750 - val_acc: 0.9212\n",
      "Epoch 420/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.5389 - val_acc: 0.9162\n",
      "Epoch 421/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.5383 - val_acc: 0.9249\n",
      "Epoch 422/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0192 - acc: 0.9949 - val_loss: 0.5117 - val_acc: 0.9162\n",
      "Epoch 423/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0164 - acc: 0.9958 - val_loss: 0.5166 - val_acc: 0.9184\n",
      "Epoch 424/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.5503 - val_acc: 0.9068\n",
      "Epoch 425/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.5291 - val_acc: 0.9104\n",
      "Epoch 426/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0162 - acc: 0.9955 - val_loss: 0.5174 - val_acc: 0.9162\n",
      "Epoch 427/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0160 - acc: 0.9960 - val_loss: 0.5356 - val_acc: 0.9118\n",
      "Epoch 428/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.5843 - val_acc: 0.9155\n",
      "Epoch 429/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0256 - acc: 0.9953 - val_loss: 0.8774 - val_acc: 0.8844\n",
      "Epoch 430/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0233 - acc: 0.9951 - val_loss: 0.5021 - val_acc: 0.9234\n",
      "Epoch 431/500\n",
      "44/44 [==============================] - 13s 285ms/step - loss: 0.0035 - acc: 0.9995 - val_loss: 0.6450 - val_acc: 0.9082\n",
      "Epoch 432/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0102 - acc: 0.9962 - val_loss: 0.5573 - val_acc: 0.9147\n",
      "Epoch 433/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0192 - acc: 0.9949 - val_loss: 0.6325 - val_acc: 0.9126\n",
      "Epoch 434/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0135 - acc: 0.9967 - val_loss: 0.5441 - val_acc: 0.9162\n",
      "Epoch 435/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0056 - acc: 0.9989 - val_loss: 0.5601 - val_acc: 0.9126\n",
      "Epoch 436/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0201 - acc: 0.9964 - val_loss: 0.5295 - val_acc: 0.9176\n",
      "Epoch 437/500\n",
      "44/44 [==============================] - 12s 284ms/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.5247 - val_acc: 0.9140\n",
      "Epoch 438/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 0.4840 - val_acc: 0.9241\n",
      "Epoch 439/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0072 - acc: 0.9977 - val_loss: 0.5005 - val_acc: 0.9155\n",
      "Epoch 440/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.5569 - val_acc: 0.9198\n",
      "Epoch 441/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.5929 - val_acc: 0.9140\n",
      "Epoch 442/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0092 - acc: 0.9977 - val_loss: 0.4901 - val_acc: 0.9205\n",
      "Epoch 443/500\n",
      "44/44 [==============================] - 12s 285ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.5523 - val_acc: 0.9198\n",
      "Epoch 444/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0035 - acc: 0.9995 - val_loss: 0.5311 - val_acc: 0.9126\n",
      "Epoch 445/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.5718 - val_acc: 0.9184\n",
      "Epoch 446/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.5499 - val_acc: 0.9104\n",
      "Epoch 447/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0075 - acc: 0.9986 - val_loss: 0.5544 - val_acc: 0.9205\n",
      "Epoch 448/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0081 - acc: 0.9982 - val_loss: 0.5467 - val_acc: 0.9227\n",
      "Epoch 449/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.5444 - val_acc: 0.9176\n",
      "Epoch 450/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.6027 - val_acc: 0.9234\n",
      "Epoch 451/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0052 - acc: 0.9986 - val_loss: 0.5450 - val_acc: 0.9176\n",
      "Epoch 452/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0435 - acc: 0.9910 - val_loss: 0.5953 - val_acc: 0.9212\n",
      "Epoch 453/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.5792 - val_acc: 0.9212\n",
      "Epoch 454/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.5378 - val_acc: 0.9234\n",
      "Epoch 455/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0165 - acc: 0.9957 - val_loss: 0.5564 - val_acc: 0.9241\n",
      "Epoch 456/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0187 - acc: 0.9953 - val_loss: 0.5828 - val_acc: 0.9090\n",
      "Epoch 457/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0197 - acc: 0.9955 - val_loss: 0.5130 - val_acc: 0.9169\n",
      "Epoch 458/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0236 - acc: 0.9933 - val_loss: 0.4980 - val_acc: 0.9126\n",
      "Epoch 459/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.5021 - val_acc: 0.9227\n",
      "Epoch 460/500\n",
      "44/44 [==============================] - 13s 289ms/step - loss: 0.0107 - acc: 0.9978 - val_loss: 0.5417 - val_acc: 0.9191\n",
      "Epoch 461/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.5005 - val_acc: 0.9212\n",
      "Epoch 462/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0161 - acc: 0.9953 - val_loss: 0.5766 - val_acc: 0.9111\n",
      "Epoch 463/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.5441 - val_acc: 0.9249\n",
      "Epoch 464/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0241 - acc: 0.9960 - val_loss: 0.5321 - val_acc: 0.9270\n",
      "Epoch 465/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.5303 - val_acc: 0.9249\n",
      "Epoch 466/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0087 - acc: 0.9984 - val_loss: 0.5523 - val_acc: 0.9162\n",
      "Epoch 467/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.5770 - val_acc: 0.9184\n",
      "Epoch 468/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.5655 - val_acc: 0.9256\n",
      "Epoch 469/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0183 - acc: 0.9967 - val_loss: 0.5333 - val_acc: 0.9220\n",
      "Epoch 470/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.7061 - val_acc: 0.9097\n",
      "Epoch 471/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0118 - acc: 0.9980 - val_loss: 0.5470 - val_acc: 0.9184\n",
      "Epoch 472/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.5797 - val_acc: 0.9169\n",
      "Epoch 473/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.5294 - val_acc: 0.9292\n",
      "Epoch 474/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0169 - acc: 0.9960 - val_loss: 0.5588 - val_acc: 0.9227\n",
      "Epoch 475/500\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.5611 - val_acc: 0.9227\n",
      "Epoch 476/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0168 - acc: 0.9962 - val_loss: 0.5548 - val_acc: 0.9285\n",
      "Epoch 477/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0176 - acc: 0.9964 - val_loss: 0.5946 - val_acc: 0.9068\n",
      "Epoch 478/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.5619 - val_acc: 0.9176\n",
      "Epoch 479/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0106 - acc: 0.9982 - val_loss: 0.5589 - val_acc: 0.9198\n",
      "Epoch 480/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.5976 - val_acc: 0.9162\n",
      "Epoch 481/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0426 - acc: 0.9899 - val_loss: 0.5225 - val_acc: 0.9010\n",
      "Epoch 482/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0594 - acc: 0.9872 - val_loss: 0.4345 - val_acc: 0.9184\n",
      "Epoch 483/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0415 - acc: 0.9924 - val_loss: 0.4460 - val_acc: 0.9133\n",
      "Epoch 484/500\n",
      "44/44 [==============================] - 12s 283ms/step - loss: 0.0341 - acc: 0.9919 - val_loss: 0.4950 - val_acc: 0.9075\n",
      "Epoch 485/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0227 - acc: 0.9930 - val_loss: 0.4516 - val_acc: 0.9249\n",
      "Epoch 486/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.5540 - val_acc: 0.9097\n",
      "Epoch 487/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0133 - acc: 0.9967 - val_loss: 0.4902 - val_acc: 0.9184\n",
      "Epoch 488/500\n",
      "44/44 [==============================] - 12s 278ms/step - loss: 0.0124 - acc: 0.9973 - val_loss: 0.4994 - val_acc: 0.9205\n",
      "Epoch 489/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.5362 - val_acc: 0.9220\n",
      "Epoch 490/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0136 - acc: 0.9969 - val_loss: 0.5211 - val_acc: 0.9249\n",
      "Epoch 491/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.5138 - val_acc: 0.9220\n",
      "Epoch 492/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0145 - acc: 0.9973 - val_loss: 0.4810 - val_acc: 0.9184\n",
      "Epoch 493/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0073 - acc: 0.9982 - val_loss: 0.5789 - val_acc: 0.9155\n",
      "Epoch 494/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.5408 - val_acc: 0.9234\n",
      "Epoch 495/500\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.0074 - acc: 0.9973 - val_loss: 0.5541 - val_acc: 0.9176\n",
      "Epoch 496/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.7483 - val_acc: 0.8981\n",
      "Epoch 497/500\n",
      "44/44 [==============================] - 12s 281ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.5869 - val_acc: 0.9104\n",
      "Epoch 498/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0111 - acc: 0.9966 - val_loss: 0.5557 - val_acc: 0.9198\n",
      "Epoch 499/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.5270 - val_acc: 0.9212\n",
      "Epoch 500/500\n",
      "44/44 [==============================] - 12s 280ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.5418 - val_acc: 0.9169\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim, output_dim)) # parameter input_length not required, because no flattening needed (using RNN layer now, not Dense layer)\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    epochs=500,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ac84537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T12:04:32.920064Z",
     "iopub.status.busy": "2022-05-07T12:04:32.919126Z",
     "iopub.status.idle": "2022-05-07T12:04:32.924381Z",
     "shell.execute_reply": "2022-05-07T12:04:32.924857Z"
    },
    "papermill": {
     "duration": 7.216931,
     "end_time": "2022-05-07T12:04:32.924996",
     "exception": false,
     "start_time": "2022-05-07T12:04:25.708065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 3)           15        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               67584     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 67,728\n",
      "Trainable params: 67,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b3a5c09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T12:04:48.280250Z",
     "iopub.status.busy": "2022-05-07T12:04:48.279413Z",
     "iopub.status.idle": "2022-05-07T12:04:48.969580Z",
     "shell.execute_reply": "2022-05-07T12:04:48.970002Z"
    },
    "papermill": {
     "duration": 8.104837,
     "end_time": "2022-05-07T12:04:48.970157",
     "exception": false,
     "start_time": "2022-05-07T12:04:40.865320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.subplots(figsize=(6,7))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation')\n",
    "plt.xlabel('Epochs', fontsize=25, labelpad=20)\n",
    "plt.ylabel('Accuracy score [%]',fontsize=25, labelpad=20)\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "plt.legend(loc=4, fontsize=20)\n",
    "\n",
    "plt.savefig('max_len_nuc.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1879bc97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T12:05:03.864718Z",
     "iopub.status.busy": "2022-05-07T12:05:03.863818Z",
     "iopub.status.idle": "2022-05-07T12:05:07.632740Z",
     "shell.execute_reply": "2022-05-07T12:05:07.632207Z"
    },
    "papermill": {
     "duration": 11.161135,
     "end_time": "2022-05-07T12:05:07.632876",
     "exception": false,
     "start_time": "2022-05-07T12:04:56.471741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9219653010368347\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6258.196104,
   "end_time": "2022-05-07T12:05:17.833160",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-07T10:20:59.637056",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
